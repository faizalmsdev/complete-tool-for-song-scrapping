{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acccca0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Loading existing metadata...\n",
      "   ✅ Loaded 2152 existing songs\n",
      "   ✅ Loaded 17 existing playlists\n",
      "   ✅ Loaded mappings for 2152 songs\n",
      "📊 Loaded totals:\n",
      "   • Songs: 2152\n",
      "   • Playlists: 17\n",
      "   • Mappings: 2152\n",
      "✅ Found existing metadata - will merge new data with existing data\n",
      "🎵 Starting incremental consolidation process...\n",
      "📁 Base folder: songs\n",
      "📁 Output folder: consolidated_music\n",
      "📂 Found 1 playlist folders\n",
      "🆕 Processing new playlist: Best of tamil songs 2010 2024\n",
      "   📎 Duplicate found: Omana-Penne-AR-Rahman-Benny-Dayal-Kalyani-Menon.mp3 (existing: song_47b8323eabdb)\n",
      "   📎 Duplicate found: Yaanji-From-Vikram-Vedha-Sam-CS-Anirudh-Ravichander-Shakthisree-Gopalan.mp3 (existing: song_08d629b4fcbf)\n",
      "   📎 Duplicate found: Megham-Karukatha-From-Thiruchitrambalam-Dhanush-Anirudh-Ravichander.mp3 (existing: song_08d25ca059f8)\n",
      "   📎 Duplicate found: Koodamela-Koodavechi-D-Imman-VV-Prassanna-Vandana-Srinivasan.mp3 (existing: song_a33b3161ca83)\n",
      "   📎 Duplicate found: Unakaga-AR-Rahman-Sreekanth-Hariharan-Madhura-Dhara-Talluri.mp3 (existing: song_3438090cf1fe)\n",
      "   📎 Duplicate found: Imaye-Imaye-G-V-Prakash-Shakthisree-Gopalan.mp3 (existing: song_2a313737c158)\n",
      "   📎 Duplicate found: Kurumba-Fathers-Love-D-Imman-Sid-Sriram-Madhan-Karky.mp3 (existing: song_46eb545a0809)\n",
      "   📎 Duplicate found: Un-Vizhigalil-Anirudh-Ravichander-Shruti-Haasan.mp3 (existing: song_3afbd2b96bc9)\n",
      "   📎 Duplicate found: Kanave-Kanave-Anirudh-Ravichander.mp3 (existing: song_3cd1ee8dc7bd)\n",
      "   ✅ Copied: Azhagai-From-Iraivan-Yuvan-Shankar-Raja-Sanjith-Hegde-Kharesma-Ravichandran.mp3 -> song_410e43ab3601.mp3\n",
      "   ✅ Copied: Ratchasa-Maamaney-From-Ponniyin-Selvan-Part-1-AR-Rahman-Shreya-Ghoshal-Palakad-Sreeram-Mahesh-Vinaya.mp3 -> song_66f81ed5cfd1.mp3\n",
      "   ✅ Copied: Idhu-Pola-From-Iraivan-Yuvan-Shankar-Raja-Shakthisree-Gopalan.mp3 -> song_0006b4b44771.mp3\n",
      "   📎 Duplicate found: Kurumugil-From-Sita-Ramam-Tamil-Vishal-Chandrashekhar-Sai-Vignesh.mp3 (existing: song_45ee0bf04b3b)\n",
      "   📎 Duplicate found: Kanja-Poovu-Kannala-From-Viruman-Yuvan-Shankar-Raja-Sid-Sriram.mp3 (existing: song_bd41cd36d258)\n",
      "   📎 Duplicate found: Arabic-Kuthu-Halamithi-Habibo-From-Beast-Anirudh-Ravichander-Jonita-Gandhi.mp3 (existing: song_8933d28c63e9)\n",
      "   ✅ Copied: Hey-Nijame-Darbuka-Siva-Bombay-Jayashri.mp3 -> song_bbe62f83bf7f.mp3\n",
      "   ✅ Copied: Paartha-Nyabhagam-Girishh-G-Viswananthan-Ramamoorthy-Shreya-Ghoshal.mp3 -> song_41d1205da788.mp3\n",
      "   ✅ Copied: Uyir-Urugudhey-From-Cobra-AR-Rahman.mp3 -> song_bc204d1d0e17.mp3\n",
      "   ✅ Copied: Rendu-Raaja-Yuvan-Shankar-Raja-Dhanush.mp3 -> song_b4b4b1b32ab1.mp3\n",
      "   ✅ Copied: Pinju-Pinju-Mazhai-Yuvan-Shankar-Raja-Sid-Sriram.mp3 -> song_61eb8aee19ab.mp3\n",
      "   📎 Duplicate found: Unna-Nenachadhum-AR-Rahman-Shreya-Ghoshal-Sarthak-Kalyani.mp3 (existing: song_5fc3bd3a7521)\n",
      "   ✅ Copied: Nenjellam-From-Sinam-G-V-Prakash-Sivaangi-Krishnakumar-Shabir-Sulthan.mp3 -> song_5718f0c3737a.mp3\n",
      "   ✅ Copied: Kylaa-From-Captain-Srinisha-Jayaseelan-Yazin-Nizar-D-Imman-Ramajogayya-Shastri.mp3 -> song_b0b5229e2453.mp3\n",
      "   ✅ Copied: En-Vazhkkai-Praji-Panikkassery-Sanoop-Kumar-Aswathi-Pappan.mp3 -> song_60e346892942.mp3\n",
      "   ✅ Copied: Tharangini-AR-Rahman-Sarthak-Kalyani-Mira-Sengupta.mp3 -> song_3fbd0fcd5c10.mp3\n",
      "   📎 Duplicate found: Unna-Nenachadhum-AR-Rahman-Shreya-Ghoshal-Sarthak-Kalyani.mp3 (existing: song_5fc3bd3a7521)\n",
      "   📎 Duplicate found: Bae-From-Don-Anirudh-Ravichander-Adithya-RK.mp3 (existing: song_db84b1797dcf)\n",
      "   📎 Duplicate found: Dippam-Dappam-From-Kaathuvaakula-Rendu-Kaadhal-Anirudh-Ravichander-Anthony-Daasan.mp3 (existing: song_4081dd1651e3)\n",
      "   ✅ Copied: Two-Two-Two-From-Kanmani-Rambo-Khatija-Anirudh-Ravichander-Sahithi-Chaganti-Sanjana-Kalmanje.mp3 -> song_45395855c435.mp3\n",
      "   ✅ Copied: Saami-Saami-From-Pushpa-The-RiseTelugu-Devi-Sri-Prasad-Mounika-Yadav-Chandra-Bose.mp3 -> song_428e79b510ef.mp3\n",
      "   📎 Duplicate found: Naan-Pizhai-From-Kaathuvaakula-Rendu-Kaadhal-Anirudh-Ravichander-Ravi-G-Shashaa-Tirupati.mp3 (existing: song_16ed4eb13058)\n",
      "   📎 Duplicate found: Jalabulajangu-From-Don-Anirudh-Ravichander-Rokesh.mp3 (existing: song_54ba3661c057)\n",
      "   📎 Duplicate found: Neeyum-Naanum-Anbe-Hiphop-Tamizha-Raghu-Dixit-Sathyaprakash-D-Jithin-Raj.mp3 (existing: song_070d2939cb16)\n",
      "   📎 Duplicate found: Othaiyadi-Pathayila-Dhibu-Ninan-Thomas-Anirudh-Ravichander.mp3 (existing: song_e5615a86b31a)\n",
      "   ✅ Copied: Naan-Nee-From-Madras-Santhosh-Narayanan-Shakthisree-Gopalan-Dheekshitha.mp3 -> song_89ca8ecd50d3.mp3\n",
      "   📎 Duplicate found: Idhu-Varai-Yuvan-Shankar-Raja-Ajesh-Andrea-Jeremiah.mp3 (existing: song_c42b7fe787ef)\n",
      "   📎 Duplicate found: Kaathalae-Kaathalae-From-96-Govind-Vasantha-Chinmayi.mp3 (existing: song_ab932845b50f)\n",
      "   📎 Duplicate found: En-Kadhal-Solla-From-Paiya-Yuvan-Shankar-Raja-Tanvi-Shah.mp3 (existing: song_5c61f271dc96)\n",
      "   📎 Duplicate found: Kannazhaga-The-Kiss-of-Love-Anirudh-Ravichander-Dhanush-Shruti-Haasan.mp3 (existing: song_16381ebdfa4f)\n",
      "   ✅ Copied: Veyyon-Silli-G-V-Prakash-Harish-Sivaramakrishnan.mp3 -> song_a8d08d93f81f.mp3\n",
      "   📎 Duplicate found: Un-Mele-Oru-Kannu-D-Imman-Jithin-Raj-Mahalakshmi-Iyer.mp3 (existing: song_66a562b67dc4)\n",
      "   📎 Duplicate found: Kaattu-Payale-G-V-Prakash-Dhee.mp3 (existing: song_cfaa93cf1756)\n",
      "   📎 Duplicate found: Idhayathai-Yedho-Ondru-Harris-Jayaraj-Chinmayi.mp3 (existing: song_b7a757592eca)\n",
      "   📎 Duplicate found: Po-Nee-Po-The-Pain-of-Love-Anirudh-Ravichander-Mohit-Chauhan.mp3 (existing: song_ad432bc3905d)\n",
      "   📎 Duplicate found: Yembuttu-Irukkuthu-Aasai-D-Imman-Sean-Roldan-Kalyani-Nair.mp3 (existing: song_9ffc0f4c206c)\n",
      "   📎 Duplicate found: Pookkal-Pookkum-G-V-Prakash-Roop-Kumar-Rathod-Harini-Andrea-Jeremiah.mp3 (existing: song_87179519bee4)\n",
      "   📎 Duplicate found: Nee-Paartha-Vizhigal-The-Touch-of-Love-Anirudh-Ravichander-Vijay-Yesudas-Shweta-Mohan.mp3 (existing: song_b0c033d9237c)\n",
      "   ✅ Copied: Manasellam-Mazhaiye-Sonu-Nigam-Saindhavi-G-V-Prakash.mp3 -> song_9f8b3daffcac.mp3\n",
      "   📎 Duplicate found: Sollitaley-Ava-Kaadhala-D-Imman-Ranjith-Govind-Shreya-Ghoshal.mp3 (existing: song_d146ecf64c40)\n",
      "   📎 Duplicate found: Kadhaippoma-From-Oh-My-Kadavule-Leon-James-Sid-Sriram.mp3 (existing: song_239babaa5d6a)\n",
      "   📎 Duplicate found: Konjam-1-Armaan-Malik.mp3 (existing: song_3b6081745b96)\n",
      "   📎 Duplicate found: Singappenney-AR-Rahman-Shashaa-Tirupati.mp3 (existing: song_04e7b690d8ac)\n",
      "   ✅ Copied: Vinmeen-From-Thegidi-Nivas-K-Prasanna-Abhay-Jodhpurkar-Saindhavi.mp3 -> song_cf36f688c111.mp3\n",
      "   📎 Duplicate found: Sandakari-Neethan-From-Sangathamizhan-Vivek-Mervin-Anirudh-Ravichander-Jonita-Gandhi-Mervin-Solomon.mp3 (existing: song_4925f27f8c31)\n",
      "   ✅ Copied: Sara-Sara-Saara-Kathu-From-Vaagai-Sooda-Vaa-Ghibran-Chinmayi.mp3 -> song_65a7e06ff5b1.mp3\n",
      "   📎 Duplicate found: Yathe-Yathe-G-V-Prakash.mp3 (existing: song_87e4a00d6cbe)\n",
      "   📎 Duplicate found: Neeyae-Vivek-Mervin-Arijit-Singh-Mervin-Solomon.mp3 (existing: song_030e91d3f5d7)\n",
      "   📎 Duplicate found: Marappadhilai-Nenje-Additional-Song-Leon-James-Sudharshan-Ashok.mp3 (existing: song_073b9e1d43b6)\n",
      "   📎 Duplicate found: En-Iniya-Thanimaye-D-Imman-Sid-Sriram-Madhan-Karky.mp3 (existing: song_99241b93b562)\n",
      "   📎 Duplicate found: Rowdy-Baby-Yuvan-Shankar-Raja-Dhanush-Dhee.mp3 (existing: song_871cd6b273c0)\n",
      "   📎 Duplicate found: Idhazhin-Oram-The-Innocence-of-Love-Anirudh-Ravichander-Ajesh.mp3 (existing: song_f904bcb561f8)\n",
      "   📎 Duplicate found: Anji-Manikku-From-Puppy-Dharan-Kumar-Yuvan-Shankar-Raja-Shashaa-Tirupati.mp3 (existing: song_a6ccda515b3b)\n",
      "   📎 Duplicate found: En-Jeevan-G-V-Prakash-Hariharan-Saindhavi-Vaikom-Vijayalakshmi.mp3 (existing: song_0d9b5f90bacf)\n",
      "   📎 Duplicate found: Gaandu-Kannamma-Vivek-Mervin.mp3 (existing: song_bcd3370b1115)\n",
      "   📎 Duplicate found: Idhu-Dhaan-From-Sivappu-Manjal-Pachai-Siddhu-Kumar-Naresh-Iyer-Shashaa-Tirupati.mp3 (existing: song_deffdc82e8b1)\n",
      "   📎 Duplicate found: Enna-Nadanthalum-From-Meesaya-Murukku-Kaushik-Krish-Hiphop-Tamizha.mp3 (existing: song_dfeac07c36fd)\n",
      "   📎 Duplicate found: Anbe-Anbe-From-Darling-G-V-Prakash.mp3 (existing: song_20254d5657d7)\n",
      "   📎 Duplicate found: Enakenna-Yaarum-Illaye-From-Aakko-Anirudh-Ravichander.mp3 (existing: song_f8d9b912fd7d)\n",
      "   📎 Duplicate found: Oh-Baby-Girl-Achu-Hemachandra-Vedala.mp3 (existing: song_3eac628e59ee)\n",
      "   📎 Duplicate found: Pallikoodam-The-Farewell-Song-Hiphop-Tamizha-Sanjith-Hegde.mp3 (existing: song_77f8f8a4f522)\n",
      "   📎 Duplicate found: Idhayathai-Yedho-Ondru-Harris-Jayaraj-Chinmayi.mp3 (existing: song_b7a757592eca)\n",
      "   ✅ Copied: Kadhalan-Havoc-Mathan-Havoc-Naven.mp3 -> song_ad228a23c8a3.mp3\n",
      "   📎 Duplicate found: Yedho-Ondru-Ennai-From-Paiya-Yuvan-Shankar-Raja.mp3 (existing: song_ea12e4bee9a3)\n",
      "   📎 Duplicate found: Andha-Kanna-Paathaakaa-Anirudh-Ravichander-Yuvan-Shankar-Raja.mp3 (existing: song_299ffea3b797)\n",
      "   📎 Duplicate found: Maya-Mugen-Rao.mp3 (existing: song_f2e2ce2d08b0)\n",
      "   📎 Duplicate found: Usure-From-Sivappu-Manjal-Pachai-Siddhu-Kumar-Sudharshan-Ashok-Jothi-Pushpa.mp3 (existing: song_5aeb6362db43)\n",
      "   📎 Duplicate found: Pogiren-Mugen-Rao-Prashan-Sean.mp3 (existing: song_5ee6e687da63)\n",
      "   ✅ Copied: Thaabangale-Govind-Vasantha-Chinmayi-Pradeep-Kumar.mp3 -> song_a4d64d3b41d2.mp3\n",
      "   ✅ Copied: Hold-Me-Now-Sanjith-Hegde-Thurga.mp3 -> song_ad4e594372b8.mp3\n",
      "   📎 Duplicate found: Raati-Madras-Gig-Santhosh-Dhayanidhi-Bamba-Bakya.mp3 (existing: song_45894d548884)\n",
      "   📎 Duplicate found: Pirai-Thedum-Saindhavi-G-V-Prakash.mp3 (existing: song_9045151fd344)\n",
      "   ✅ Copied: Unkoodave-Porakkanum-Brothers-Version-D-Imman-Sid-Sriram.mp3 -> song_1fab13544aa1.mp3\n",
      "   📎 Duplicate found: Kannamma-From-Ispade-Rajavum-Idhaya-Raniyum-Sam-CS-Anirudh-Ravichander.mp3 (existing: song_81592f37cf0b)\n",
      "   📎 Duplicate found: Sathiyama-Mugen-Rao-Priyashankari.mp3 (existing: song_0c8195454dfe)\n",
      "   📎 Duplicate found: Un-Vizhigalil-From-Darling-Harini.mp3 (existing: song_a93b8eac998d)\n",
      "   📎 Duplicate found: Andha-Kanna-Paathaakaa-Anirudh-Ravichander-Yuvan-Shankar-Raja.mp3 (existing: song_299ffea3b797)\n",
      "   📎 Duplicate found: Yedho-Ondru-Ennai-From-Paiya-Yuvan-Shankar-Raja.mp3 (existing: song_ea12e4bee9a3)\n",
      "   ✅ Copied: Chiru-Chiru-Yuvan-Shankar-Raja-Haricharan-Sagar-Desai.mp3 -> song_1da0ce84422d.mp3\n",
      "   📎 Duplicate found: Iragai-Poley-Yuvan-Shankar-Raja-Tanvi-Shah.mp3 (existing: song_ea2808f3558a)\n",
      "   📎 Duplicate found: Enkeyoo-Partha-Yuvan-Shankar-Raja-Udit-Narayan.mp3 (existing: song_74c922cf261d)\n",
      "   ✅ Copied: Gaandakannazhagi-D-Imman-Anirudh-Ravichander-Neeti-Mohan.mp3 -> song_58e80ed7c01f.mp3\n",
      "   📎 Duplicate found: Venmegam-Yuvan-Shankar-Raja-Hariharan.mp3 (existing: song_254990dd71c1)\n",
      "   ✅ Copied: Mella-Sirithai-From-Kalyana-Samayal-Saadham-Arrora-Haricharan-Chinmayi.mp3 -> song_8906531d6301.mp3\n",
      "   ✅ Copied: Mannurunda-G-V-Prakash-Senthil-Ganesh.mp3 -> song_22e897b52d86.mp3\n",
      "   📎 Duplicate found: Ayyayo-G-V-Prakash-S-P-Balasubrahmanyam-SP-Charan-Prashanthini.mp3 (existing: song_2371a023ffd8)\n",
      "   📎 Duplicate found: Kaathodu-Kaathanen-From-Jail-G-V-Prakash-Dhanush-Aditi-Rao-Hydari.mp3 (existing: song_6061714295af)\n",
      "   📎 Duplicate found: Otha-Sollaala-G-V-Prakash-Velmurugan.mp3 (existing: song_c28f04d35406)\n",
      "   ✅ Copied: Pilla-Puli-G-V-Prakash-Anurag-Kulkarni.mp3 -> song_a90989a6a9a1.mp3\n",
      "   ✅ Copied: Kaatuka-Kanule-G-V-Prakash-Dhee.mp3 -> song_94acd7bcd845.mp3\n",
      "   📎 Duplicate found: Senthoora-D-Imman-Luksimi-Sivaneswaralingam.mp3 (existing: song_4740952729fc)\n",
      "   📎 Duplicate found: Onnavitta-Yaarum-Yenakilla-Version-1-D-Imman-Sean-Roldan-Shreya-Ghoshal.mp3 (existing: song_a8032f2dbccc)\n",
      "   📎 Duplicate found: En-Iniya-Thanimaye-D-Imman-Sid-Sriram-Madhan-Karky.mp3 (existing: song_99241b93b562)\n",
      "   📎 Duplicate found: Pesadhe-From-Thirudan-Police-Yuvan-Shankar-Raja-Harihara-Sudhan-Pooja.mp3 (existing: song_89a98eae45ad)\n",
      "   📎 Duplicate found: Kadhal-Kanave-From-Mundasupatti-Sean-Roldan-Pradeep-Kumar-Kalyani-Nair.mp3 (existing: song_2704aae91b1e)\n",
      "   ✅ Copied: Enthaaraa-Enthaaraa-From-Thirumanam-Enum-Nikkah-Ghibran-Shadab-Faridi-Chinmayi.mp3 -> song_51a4d5e9cf86.mp3\n",
      "   📎 Duplicate found: Agayam-Theepiditha-From-Madras-Santhosh-Narayanan-Pradeep-Kumar.mp3 (existing: song_eb77477fae8b)\n",
      "   ✅ Copied: Hey-Baby-From-Raja-Rani-G-V-Prakash-Gana-Bala-Aishwarya.mp3 -> song_729b3dc1ac41.mp3\n",
      "   ✅ Copied: Idhu-Enna-From-Mundasupatti-Sean-Roldan-Haricharan-Kalyani-Nair.mp3 -> song_c2ac4106ee69.mp3\n",
      "   ✅ Copied: Chillendra-Chillendra-From-Thirumanam-Enum-Nikkah-Ghibran-Sundar-Narayana-Rao-Kaushiki-Chakraborty-M.mp3 -> song_414ec056a8fb.mp3\n",
      "   ✅ Copied: Injathea-From-Nedunchalai-C-Sathya-Roop-Kumar-Rathod-Madhusree-Yazin-Nizar.mp3 -> song_eef40e302df6.mp3\n",
      "   📎 Duplicate found: Kadhal-Yennulle-From-Neram-Rajesh-Murugesan-Ranjith-Govind.mp3 (existing: song_b82d0461c6a4)\n",
      "   ✅ Copied: Boomiyil-From-The-Villa-Santhosh-Narayanan-Pradeep-Kumar.mp3 -> song_f465d23237df.mp3\n",
      "   ✅ Copied: Munne-Yen-Munne-From-Sathuranka-Vettai-Sean-Roldan-Sathyaprakash.mp3 -> song_6ee53405f59f.mp3\n",
      "   ✅ Copied: Yaar-Ezhudhiyadho-From-Thegidi-Nivas-K-Prasanna-Sathya-Prakash-Dharmar.mp3 -> song_5e9ac50648c8.mp3\n",
      "   ✅ Copied: Narumugaye-From-Sundaattam-Britto-Aalaap-Raju-Madhu-Bala.mp3 -> song_ccacf075bf75.mp3\n",
      "   ✅ Copied: Yaeley-Yaeley-Maruthu-From-Pandiyanaadu-D-Imman-Sooraj-Santhosh.mp3 -> song_b9221bffc60c.mp3\n",
      "   ✅ Copied: Yaaro-Ival-From-Thirumanam-Enum-Nikkah-Ghibran-Yazin-Nizar.mp3 -> song_8aef641da8f8.mp3\n",
      "   ✅ Copied: Aasai-Oru-Pulveli-From-Atta-Kathi-Santhosh-Narayanan-Pradeep-Kalyani-Nair.mp3 -> song_affdd2de8c89.mp3\n",
      "   ✅ Copied: Adikkadi-From-Ponmaalai-Pozhudhu-C-Sathya-Hariharan-Sathyan.mp3 -> song_9c49f053a3ce.mp3\n",
      "   ✅ Copied: Imaye-Imaye-From-Raja-Rani-G-V-Prakash-Shakthisree-Gopalan.mp3 -> song_314a6488da14.mp3\n",
      "   ✅ Copied: Iravugalil-From-Ponmaalai-Pozhudhu-C-Sathya-Karthik-Steve-Vatz.mp3 -> song_dd4bbccaed67.mp3\n",
      "   ✅ Copied: Rasa-Magarasa-From-Mundasupatti-Sean-Roldan-Rita-Thyagarajan-Anthony-Daasan.mp3 -> song_b189e1884be5.mp3\n",
      "   ✅ Copied: Mogathirai-From-Pizza-Santhosh-Narayanan-Pradeep-Vijay.mp3 -> song_10346f0ae744.mp3\n",
      "   ✅ Copied: Yaarum-Paakkaama-From-Nerungi-Vaa-Muthamidathe-Madley-Blues-Chinmayi.mp3 -> song_77fa144d1138.mp3\n",
      "   ✅ Copied: Kannamma-From-Jigarthanda-Santhosh-Narayanan-Rita-Thyagarajan-Anthony-Daasan.mp3 -> song_bc4b6c517f7c.mp3\n",
      "   ✅ Copied: Chillena-From-Raja-Rani-G-V-Prakash-Clinton-Cerejo-Alphonse-Alka-Ajith.mp3 -> song_a3ed3b736192.mp3\n",
      "   ✅ Copied: Manasula-Soora-Kaathey-From-Cuckoo-Santhosh-Narayanan-R-R-Divya-Ramani.mp3 -> song_26c0415d5b18.mp3\n",
      "   ✅ Copied: Poo-Avizhum-Pozhudhil-From-Enakkul-Oruvan-Santhosh-Narayanan-Pradeep-Kumar.mp3 -> song_faab7ad62876.mp3\n",
      "   ✅ Copied: Kadhala-Kadhala-From-Sathuranka-Vettai-Sean-Roldan-Kalyani-Nair.mp3 -> song_a2c3d64fb65e.mp3\n",
      "   ✅ Copied: Agasatha-From-Cuckoo-Santhosh-Narayanan-Kalyani-Nair-Pradeep-Kumar.mp3 -> song_36fa3efd8a9b.mp3\n",
      "   📎 Duplicate found: Kadhal-Kanave-From-Mundasupatti-Sean-Roldan-Pradeep-Kumar-Kalyani-Nair.mp3 (existing: song_2704aae91b1e)\n",
      "   📎 Duplicate found: Pesadhe-From-Thirudan-Police-Yuvan-Shankar-Raja-Harihara-Sudhan-Pooja.mp3 (existing: song_89a98eae45ad)\n",
      "   📎 Duplicate found: Yennai-Maatrum-Kadhale-Sid-Sriram.mp3 (existing: song_fb49ccffa783)\n",
      "   📎 Duplicate found: Anbil-Avan-AR-Rahman-Chinmayi-Devan-Ekambaram.mp3 (existing: song_1f536bba5b5a)\n",
      "   📎 Duplicate found: Rendu-Kaadhal-From-Kaathuvaakula-Rendu-Kaadhal-Anirudh-Ravichander-Shakthisree-Gopalan-Aishwarya-Sur.mp3 (existing: song_a9e2560892f7)\n",
      "   📎 Duplicate found: Maya-Nadhi-Santhosh-Narayanan-Ananthu-Pradeep-Kumar-Shweta-Mohan.mp3 (existing: song_4931ae62cad3)\n",
      "   📎 Duplicate found: Yaen-Ennai-Pirindhaai-Sid-Sriram.mp3 (existing: song_5ba998f116cb)\n",
      "\n",
      "🗑️  Found 17 orphaned playlists: {'Heal', 'Feel good tamil songs', 'Tamil songs that feel good now', 'All in one', 'Depression pain tamil songs', 'Love songs filtered by key', 'Trending now tamil', 'Soothing', 'Old songs', 'Tamilsongs best of all time', 'Hindi songs best of 2000-2025', 'Tamil love melody songs', 'Top hits', 'Latest hits tamil', 'Tamil best love feeling songs', 'Best tamil songs of all time', 'Feel it'}\n",
      "\n",
      "💾 Saving metadata...\n",
      "   📖 Loaded existing songs database with 2152 songs\n",
      "   ✅ Saved songs database with 2205 total songs\n",
      "   📖 Loaded existing playlists database with 17 playlists\n",
      "   ✅ Saved playlists database with 18 total playlists\n",
      "   📖 Loaded existing mapping database with 2152 mappings\n",
      "   ✅ Saved mapping database with 2205 total mappings\n",
      "✅ All metadata saved successfully!\n",
      "\n",
      "============================================================\n",
      "🎉 INCREMENTAL CONSOLIDATION COMPLETE\n",
      "============================================================\n",
      "🎵 Total unique songs: 130\n",
      "📋 Total playlists: 1\n",
      "📁 Songs folder: consolidated_music\\songs\n",
      "📁 Metadata folder: consolidated_music\\metadata\n",
      "\n",
      "📊 Session Statistics:\n",
      "   • Existing songs found: 2152\n",
      "   • New songs added: 53\n",
      "   • New playlists added: 1\n",
      "   • Playlists updated: 0\n",
      "   • Duplicates skipped: 84\n",
      "   • Songs added to existing playlists: 77\n",
      "\n",
      "📄 Generated/Updated files:\n",
      "   • songs_database.json (complete song information)\n",
      "   • playlists_database.json (playlist information with song lists)\n",
      "   • song_playlist_mapping.json (song to playlist relationships)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Set\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "class IncrementalSongConsolidator:\n",
    "    def __init__(self, base_songs_folder: str, output_folder: str = \"consolidated_songs\"):\n",
    "        self.base_songs_folder = Path(base_songs_folder)\n",
    "        self.output_folder = Path(output_folder)\n",
    "        self.songs_output = self.output_folder / \"songs\"\n",
    "        self.metadata_output = self.output_folder / \"metadata\"\n",
    "        \n",
    "        # Create output directories\n",
    "        self.songs_output.mkdir(parents=True, exist_ok=True)\n",
    "        self.metadata_output.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Data structures to track songs and playlists\n",
    "        self.unique_songs = {}  # song_id -> song_info (changed from track_uri as key)\n",
    "        self.playlist_data = {}  # playlist_name -> playlist_info\n",
    "        self.song_to_playlists = {}  # song_id -> list of playlist names\n",
    "        \n",
    "        # Track processed playlists to avoid reprocessing\n",
    "        self.processed_playlists = set()\n",
    "        \n",
    "        # Lookup tables for efficient searching\n",
    "        self.uri_to_song_id = {}  # track_uri -> song_id\n",
    "        self.name_artist_to_song_id = {}  # normalized_name_artist -> song_id\n",
    "        \n",
    "        # Statistics\n",
    "        self.stats = {\n",
    "            'new_songs_added': 0,\n",
    "            'new_playlists_added': 0,\n",
    "            'duplicates_skipped': 0,\n",
    "            'playlists_updated': 0,\n",
    "            'existing_songs_found': 0,\n",
    "            'songs_added_to_existing_playlists': 0\n",
    "        }\n",
    "        \n",
    "        # Load existing metadata if available\n",
    "        self.load_existing_metadata()\n",
    "    \n",
    "    def load_existing_metadata(self):\n",
    "        \"\"\"Load existing metadata from previous runs and preserve ALL data\"\"\"\n",
    "        print(\"🔍 Loading existing metadata...\")\n",
    "        \n",
    "        songs_db_path = self.metadata_output / 'songs_database.json'\n",
    "        playlists_db_path = self.metadata_output / 'playlists_database.json'\n",
    "        mapping_db_path = self.metadata_output / 'song_playlist_mapping.json'\n",
    "        \n",
    "        # Load songs database\n",
    "        if songs_db_path.exists():\n",
    "            try:\n",
    "                with open(songs_db_path, 'r', encoding='utf-8') as f:\n",
    "                    songs_data = json.load(f)\n",
    "                    \n",
    "                # Load ALL existing songs - use song_id as primary key\n",
    "                existing_songs = songs_data.get('songs', {})\n",
    "                for song_id, song_info in existing_songs.items():\n",
    "                    self.unique_songs[song_id] = song_info\n",
    "                    \n",
    "                    # Build lookup tables for efficient duplicate detection\n",
    "                    metadata = song_info.get('metadata', {})\n",
    "                    track_uri = metadata.get('track_uri', '')\n",
    "                    if track_uri:\n",
    "                        self.uri_to_song_id[track_uri] = song_id\n",
    "                    \n",
    "                    # Create name+artist lookup\n",
    "                    track_name = metadata.get('track_name', '').lower().strip()\n",
    "                    artists = metadata.get('artists_string', '').lower().strip()\n",
    "                    if track_name and artists:\n",
    "                        key = f\"{track_name}|{artists}\"\n",
    "                        self.name_artist_to_song_id[key] = song_id\n",
    "                    \n",
    "                    self.stats['existing_songs_found'] += 1\n",
    "                \n",
    "                print(f\"   ✅ Loaded {len(self.unique_songs)} existing songs\")\n",
    "            except Exception as e:\n",
    "                print(f\"   ❌ Error loading songs database: {e}\")\n",
    "        \n",
    "        # Load playlists database  \n",
    "        if playlists_db_path.exists():\n",
    "            try:\n",
    "                with open(playlists_db_path, 'r', encoding='utf-8') as f:\n",
    "                    playlists_data = json.load(f)\n",
    "                    existing_playlists = playlists_data.get('playlists', {})\n",
    "                    \n",
    "                    # Preserve ALL existing playlist data\n",
    "                    for playlist_name, playlist_info in existing_playlists.items():\n",
    "                        self.playlist_data[playlist_name] = playlist_info\n",
    "                        # Don't mark as processed yet - let the timestamp check decide\n",
    "                \n",
    "                print(f\"   ✅ Loaded {len(self.playlist_data)} existing playlists\")\n",
    "            except Exception as e:\n",
    "                print(f\"   ❌ Error loading playlists database: {e}\")\n",
    "        \n",
    "        # Load song-to-playlist mapping\n",
    "        if mapping_db_path.exists():\n",
    "            try:\n",
    "                with open(mapping_db_path, 'r', encoding='utf-8') as f:\n",
    "                    mapping_data = json.load(f)\n",
    "                    existing_mappings = mapping_data.get('song_to_playlists', {})\n",
    "                    \n",
    "                    # Preserve ALL existing mappings\n",
    "                    for song_id, playlists in existing_mappings.items():\n",
    "                        self.song_to_playlists[song_id] = playlists.copy()\n",
    "                \n",
    "                print(f\"   ✅ Loaded mappings for {len(self.song_to_playlists)} songs\")\n",
    "            except Exception as e:\n",
    "                print(f\"   ❌ Error loading song-playlist mapping: {e}\")\n",
    "        \n",
    "        # Verify data consistency\n",
    "        total_loaded = len(self.unique_songs) + len(self.playlist_data) + len(self.song_to_playlists)\n",
    "        \n",
    "        if total_loaded > 0:\n",
    "            print(f\"📊 Loaded totals:\")\n",
    "            print(f\"   • Songs: {len(self.unique_songs)}\")\n",
    "            print(f\"   • Playlists: {len(self.playlist_data)}\")  \n",
    "            print(f\"   • Mappings: {len(self.song_to_playlists)}\")\n",
    "            print(\"✅ Found existing metadata - will merge new data with existing data\")\n",
    "        else:\n",
    "            print(\"🆕 No existing metadata found - starting fresh\")\n",
    "    \n",
    "    def generate_song_id(self, track_name: str, artists: str) -> str:\n",
    "        \"\"\"Generate a unique ID for a song based on track name and artists\"\"\"\n",
    "        # Clean the string for ID generation\n",
    "        clean_string = f\"{track_name}_{artists}\".lower()\n",
    "        clean_string = re.sub(r'[^a-z0-9_]', '', clean_string)\n",
    "        \n",
    "        # Generate a hash for uniqueness\n",
    "        hash_object = hashlib.md5(clean_string.encode())\n",
    "        return f\"song_{hash_object.hexdigest()[:12]}\"\n",
    "    \n",
    "    def find_existing_song_id(self, metadata: dict) -> str:\n",
    "        \"\"\"Find existing song ID if song already exists, otherwise return None\"\"\"\n",
    "        track_uri = metadata.get('track_uri', '')\n",
    "        track_name = metadata.get('track_name', '').lower().strip()\n",
    "        artists = metadata.get('artists_string', '').lower().strip()\n",
    "        \n",
    "        # First check by URI (most reliable)\n",
    "        if track_uri and track_uri in self.uri_to_song_id:\n",
    "            return self.uri_to_song_id[track_uri]\n",
    "        \n",
    "        # Then check by name + artists\n",
    "        if track_name and artists:\n",
    "            key = f\"{track_name}|{artists}\"\n",
    "            if key in self.name_artist_to_song_id:\n",
    "                return self.name_artist_to_song_id[key]\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def normalize_filename(self, filename: str) -> str:\n",
    "        \"\"\"Normalize filename for comparison\"\"\"\n",
    "        return filename.lower().replace('-', '').replace('_', '').replace(' ', '')\n",
    "    \n",
    "    def find_song_files(self, playlist_folder: Path) -> List[Path]:\n",
    "        \"\"\"Find all audio files in a playlist folder\"\"\"\n",
    "        audio_extensions = {'.mp3', '.webm', '.wav', '.flac', '.m4a'}\n",
    "        song_files = []\n",
    "        \n",
    "        for file_path in playlist_folder.iterdir():\n",
    "            if file_path.is_file() and file_path.suffix.lower() in audio_extensions:\n",
    "                song_files.append(file_path)\n",
    "        \n",
    "        return song_files\n",
    "    \n",
    "    def playlist_needs_update(self, playlist_folder: Path, playlist_name: str) -> bool:\n",
    "        \"\"\"Check if playlist needs to be updated based on modification time or new songs\"\"\"\n",
    "        json_file = playlist_folder / \"enhanced_download_summary.json\"\n",
    "        if not json_file.exists():\n",
    "            return False\n",
    "        \n",
    "        # Always process if playlist is new\n",
    "        if playlist_name not in self.processed_playlists:\n",
    "            return True\n",
    "        \n",
    "        # Check if the enhanced_download_summary.json has been modified\n",
    "        existing_playlist = self.playlist_data.get(playlist_name, {})\n",
    "        existing_timestamp = existing_playlist.get('timestamp', '')\n",
    "        \n",
    "        try:\n",
    "            with open(json_file, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "            current_timestamp = data.get('download_info', {}).get('timestamp', '')\n",
    "            \n",
    "            # If timestamps differ, playlist needs update\n",
    "            return current_timestamp != existing_timestamp\n",
    "        except:\n",
    "            return True\n",
    "    \n",
    "    def get_existing_filename(self, song_id: str) -> str:\n",
    "        \"\"\"Get the existing filename for a song if it exists\"\"\"\n",
    "        if song_id in self.unique_songs:\n",
    "            return self.unique_songs[song_id].get('filename', '')\n",
    "        return ''\n",
    "    \n",
    "    def process_playlist_folder(self, playlist_folder: Path):\n",
    "        \"\"\"Process a single playlist folder\"\"\"\n",
    "        playlist_name = playlist_folder.name\n",
    "        json_file = playlist_folder / \"enhanced_download_summary.json\"\n",
    "        \n",
    "        # Skip folders without the JSON file\n",
    "        if not json_file.exists():\n",
    "            print(f\"⏭️  Skipping {playlist_name}: No enhanced_download_summary.json found\")\n",
    "            return\n",
    "        \n",
    "        # Check if playlist needs update\n",
    "        if not self.playlist_needs_update(playlist_folder, playlist_name):\n",
    "            print(f\"⏭️  Skipping {playlist_name}: Already up to date\")\n",
    "            return\n",
    "        \n",
    "        is_new_playlist = playlist_name not in self.processed_playlists\n",
    "        action = \"🆕 Processing new playlist\" if is_new_playlist else \"🔄 Updating playlist\"\n",
    "        print(f\"{action}: {playlist_name}\")\n",
    "        \n",
    "        try:\n",
    "            with open(json_file, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error reading JSON from {playlist_name}: {e}\")\n",
    "            return\n",
    "        \n",
    "        # Update playlist metadata (merge with existing if present)\n",
    "        download_info = data.get('download_info', {})\n",
    "        \n",
    "        if playlist_name in self.playlist_data:\n",
    "            # Update existing playlist data\n",
    "            existing_playlist = self.playlist_data[playlist_name]\n",
    "            existing_playlist.update({\n",
    "                'total_tracks': download_info.get('total_tracks', existing_playlist.get('total_tracks', 0)),\n",
    "                'successful_downloads': download_info.get('successful_downloads', existing_playlist.get('successful_downloads', 0)),\n",
    "                'source_url': download_info.get('source_url', existing_playlist.get('source_url', '')),\n",
    "                'timestamp': download_info.get('timestamp', existing_playlist.get('timestamp', '')),\n",
    "                'folder_path': str(playlist_folder),\n",
    "                'last_updated': datetime.now().isoformat()\n",
    "            })\n",
    "        else:\n",
    "            # Create new playlist entry\n",
    "            self.playlist_data[playlist_name] = {\n",
    "                'name': playlist_name,\n",
    "                'total_tracks': download_info.get('total_tracks', 0),\n",
    "                'successful_downloads': download_info.get('successful_downloads', 0),\n",
    "                'source_url': download_info.get('source_url', ''),\n",
    "                'timestamp': download_info.get('timestamp', ''),\n",
    "                'folder_path': str(playlist_folder),\n",
    "                'last_updated': datetime.now().isoformat(),\n",
    "                'created_at': datetime.now().isoformat()\n",
    "            }\n",
    "        \n",
    "        if is_new_playlist:\n",
    "            self.stats['new_playlists_added'] += 1\n",
    "        else:\n",
    "            self.stats['playlists_updated'] += 1\n",
    "        \n",
    "        # Get all song files in the folder\n",
    "        song_files = self.find_song_files(playlist_folder)\n",
    "        \n",
    "        # Process each song in the download results\n",
    "        download_results = data.get('download_results', [])\n",
    "        \n",
    "        for result in download_results:\n",
    "            if result.get('status') != 'success':\n",
    "                continue\n",
    "                \n",
    "            metadata = result.get('metadata', {})\n",
    "            filename = result.get('filename', '')\n",
    "            \n",
    "            # Find the actual file\n",
    "            matching_file = None\n",
    "            for song_file in song_files:\n",
    "                if self.normalize_filename(song_file.name) == self.normalize_filename(filename):\n",
    "                    matching_file = song_file\n",
    "                    break\n",
    "            \n",
    "            if not matching_file:\n",
    "                print(f\"⚠️  Warning: Could not find file {filename} in {playlist_name}\")\n",
    "                continue\n",
    "            \n",
    "            # Check if this song already exists\n",
    "            existing_song_id = self.find_existing_song_id(metadata)\n",
    "            \n",
    "            if existing_song_id:\n",
    "                # Song exists - add playlist to existing song\n",
    "                existing_song = self.unique_songs[existing_song_id]\n",
    "                \n",
    "                # Add playlist to song if not already there\n",
    "                if playlist_name not in existing_song.get('playlists', []):\n",
    "                    existing_song['playlists'].append(playlist_name)\n",
    "                    existing_song['last_updated'] = datetime.now().isoformat()\n",
    "                    self.stats['songs_added_to_existing_playlists'] += 1\n",
    "                \n",
    "                # Update song-to-playlist mapping\n",
    "                if existing_song_id not in self.song_to_playlists:\n",
    "                    self.song_to_playlists[existing_song_id] = []\n",
    "                if playlist_name not in self.song_to_playlists[existing_song_id]:\n",
    "                    self.song_to_playlists[existing_song_id].append(playlist_name)\n",
    "                \n",
    "                self.stats['duplicates_skipped'] += 1\n",
    "                print(f\"   📎 Duplicate found: {filename} (existing: {existing_song_id})\")\n",
    "                \n",
    "            else:\n",
    "                # New song - create entry\n",
    "                song_id = self.generate_song_id(\n",
    "                    metadata.get('track_name', ''),\n",
    "                    metadata.get('artists_string', '')\n",
    "                )\n",
    "                \n",
    "                # Determine filename - use existing if song_id already exists, otherwise create new\n",
    "                existing_filename = self.get_existing_filename(song_id)\n",
    "                if existing_filename:\n",
    "                    new_filename = existing_filename\n",
    "                else:\n",
    "                    file_extension = matching_file.suffix\n",
    "                    new_filename = f\"{song_id}{file_extension}\"\n",
    "                \n",
    "                new_file_path = self.songs_output / new_filename\n",
    "                \n",
    "                # Only copy if file doesn't exist\n",
    "                if not new_file_path.exists():\n",
    "                    try:\n",
    "                        shutil.copy2(matching_file, new_file_path)\n",
    "                        print(f\"   ✅ Copied: {filename} -> {new_filename}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"   ❌ Error copying {filename}: {e}\")\n",
    "                        continue\n",
    "                else:\n",
    "                    print(f\"   📁 File already exists: {new_filename}\")\n",
    "                \n",
    "                # Store/update song info\n",
    "                if song_id in self.unique_songs:\n",
    "                    # Update existing song entry\n",
    "                    existing_song = self.unique_songs[song_id]\n",
    "                    if playlist_name not in existing_song.get('playlists', []):\n",
    "                        existing_song['playlists'].append(playlist_name)\n",
    "                        existing_song['last_updated'] = datetime.now().isoformat()\n",
    "                else:\n",
    "                    # Create new song entry\n",
    "                    self.unique_songs[song_id] = {\n",
    "                        'song_id': song_id,\n",
    "                        'filename': new_filename,\n",
    "                        'original_filename': filename,\n",
    "                        'file_path': str(new_file_path),\n",
    "                        'metadata': metadata,\n",
    "                        'playlists': [playlist_name],\n",
    "                        'added_at': datetime.now().isoformat(),\n",
    "                        'last_updated': datetime.now().isoformat()\n",
    "                    }\n",
    "                    \n",
    "                    # Update lookup tables\n",
    "                    track_uri = metadata.get('track_uri', '')\n",
    "                    if track_uri:\n",
    "                        self.uri_to_song_id[track_uri] = song_id\n",
    "                    \n",
    "                    track_name = metadata.get('track_name', '').lower().strip()\n",
    "                    artists = metadata.get('artists_string', '').lower().strip()\n",
    "                    if track_name and artists:\n",
    "                        key = f\"{track_name}|{artists}\"\n",
    "                        self.name_artist_to_song_id[key] = song_id\n",
    "                    \n",
    "                    self.stats['new_songs_added'] += 1\n",
    "                \n",
    "                # Update song-to-playlist mapping\n",
    "                if song_id not in self.song_to_playlists:\n",
    "                    self.song_to_playlists[song_id] = []\n",
    "                if playlist_name not in self.song_to_playlists[song_id]:\n",
    "                    self.song_to_playlists[song_id].append(playlist_name)\n",
    "        \n",
    "        # Mark playlist as processed\n",
    "        self.processed_playlists.add(playlist_name)\n",
    "    \n",
    "    def cleanup_orphaned_data(self):\n",
    "        \"\"\"Remove data for playlists that no longer exist\"\"\"\n",
    "        current_playlist_folders = {f.name for f in self.base_songs_folder.iterdir() if f.is_dir()}\n",
    "        \n",
    "        # Find playlists in metadata that no longer exist\n",
    "        orphaned_playlists = set(self.playlist_data.keys()) - current_playlist_folders\n",
    "        \n",
    "        if orphaned_playlists:\n",
    "            print(f\"\\n🗑️  Found {len(orphaned_playlists)} orphaned playlists: {orphaned_playlists}\")\n",
    "            \n",
    "            # Remove orphaned playlists\n",
    "            for playlist_name in orphaned_playlists:\n",
    "                del self.playlist_data[playlist_name]\n",
    "                self.processed_playlists.discard(playlist_name)\n",
    "            \n",
    "            # Clean up song-to-playlist mappings\n",
    "            for song_id in list(self.song_to_playlists.keys()):\n",
    "                # Remove orphaned playlists from song mappings\n",
    "                original_playlists = self.song_to_playlists[song_id].copy()\n",
    "                self.song_to_playlists[song_id] = [\n",
    "                    p for p in self.song_to_playlists[song_id] \n",
    "                    if p not in orphaned_playlists\n",
    "                ]\n",
    "                \n",
    "                # Remove songs that are no longer in any playlist\n",
    "                if not self.song_to_playlists[song_id]:\n",
    "                    del self.song_to_playlists[song_id]\n",
    "            \n",
    "            # Update unique_songs playlist lists\n",
    "            for song_id in list(self.unique_songs.keys()):\n",
    "                original_playlists = self.unique_songs[song_id]['playlists'].copy()\n",
    "                self.unique_songs[song_id]['playlists'] = [\n",
    "                    p for p in self.unique_songs[song_id]['playlists']\n",
    "                    if p not in orphaned_playlists\n",
    "                ]\n",
    "                \n",
    "                # Remove songs that are no longer in any playlist\n",
    "                if not self.unique_songs[song_id]['playlists']:\n",
    "                    # Remove the physical file\n",
    "                    song_file = Path(self.unique_songs[song_id]['file_path'])\n",
    "                    if song_file.exists():\n",
    "                        try:\n",
    "                            song_file.unlink()\n",
    "                            print(f\"   🗑️  Removed orphaned song file: {song_file.name}\")\n",
    "                        except Exception as e:\n",
    "                            print(f\"   ❌ Error removing {song_file.name}: {e}\")\n",
    "                    \n",
    "                    # Remove from lookup tables\n",
    "                    metadata = self.unique_songs[song_id].get('metadata', {})\n",
    "                    track_uri = metadata.get('track_uri', '')\n",
    "                    if track_uri in self.uri_to_song_id:\n",
    "                        del self.uri_to_song_id[track_uri]\n",
    "                    \n",
    "                    track_name = metadata.get('track_name', '').lower().strip()\n",
    "                    artists = metadata.get('artists_string', '').lower().strip()\n",
    "                    if track_name and artists:\n",
    "                        key = f\"{track_name}|{artists}\"\n",
    "                        if key in self.name_artist_to_song_id:\n",
    "                            del self.name_artist_to_song_id[key]\n",
    "                    \n",
    "                    del self.unique_songs[song_id]\n",
    "    \n",
    "    def save_metadata(self):\n",
    "        \"\"\"Save consolidated metadata to JSON files - MERGE with existing data\"\"\"\n",
    "        print(\"\\n💾 Saving metadata...\")\n",
    "        \n",
    "        # 1. SONGS DATABASE - Load existing and merge\n",
    "        songs_db_path = self.metadata_output / 'songs_database.json'\n",
    "        existing_songs_db = {'songs': {}, 'stats': {}}\n",
    "        \n",
    "        if songs_db_path.exists():\n",
    "            try:\n",
    "                with open(songs_db_path, 'r', encoding='utf-8') as f:\n",
    "                    existing_songs_db = json.load(f)\n",
    "                print(f\"   📖 Loaded existing songs database with {len(existing_songs_db.get('songs', {}))} songs\")\n",
    "            except Exception as e:\n",
    "                print(f\"   ⚠️  Warning: Could not load existing songs database: {e}\")\n",
    "        \n",
    "        # Merge all songs (existing + current)\n",
    "        all_songs = existing_songs_db.get('songs', {}).copy()\n",
    "        \n",
    "        # Add/update songs from current session\n",
    "        for song_id, song_info in self.unique_songs.items():\n",
    "            all_songs[song_id] = song_info\n",
    "        \n",
    "        # Prepare stats with history\n",
    "        existing_stats = existing_songs_db.get('stats', {})\n",
    "        new_stats = {\n",
    "            'total_unique_songs': len(all_songs),\n",
    "            'total_playlists': len(self.playlist_data),\n",
    "            'generated_at': datetime.now().isoformat(),\n",
    "            'last_session_stats': self.stats.copy()\n",
    "        }\n",
    "        \n",
    "        # Preserve historical info\n",
    "        if 'first_created_at' in existing_stats:\n",
    "            new_stats['first_created_at'] = existing_stats['first_created_at']\n",
    "        else:\n",
    "            new_stats['first_created_at'] = datetime.now().isoformat()\n",
    "        \n",
    "        if 'session_history' in existing_stats:\n",
    "            new_stats['session_history'] = existing_stats['session_history'].copy()\n",
    "        else:\n",
    "            new_stats['session_history'] = []\n",
    "        \n",
    "        # Add current session to history\n",
    "        new_stats['session_history'].append({\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'stats': self.stats.copy()\n",
    "        })\n",
    "        \n",
    "        # Save songs database\n",
    "        songs_db = {\n",
    "            'songs': all_songs,\n",
    "            'stats': new_stats\n",
    "        }\n",
    "        \n",
    "        with open(songs_db_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(songs_db, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"   ✅ Saved songs database with {len(all_songs)} total songs\")\n",
    "        \n",
    "        # 2. PLAYLISTS DATABASE - Load existing and merge\n",
    "        playlists_db_path = self.metadata_output / 'playlists_database.json'\n",
    "        existing_playlists_db = {'playlists': {}, 'stats': {}}\n",
    "        \n",
    "        if playlists_db_path.exists():\n",
    "            try:\n",
    "                with open(playlists_db_path, 'r', encoding='utf-8') as f:\n",
    "                    existing_playlists_db = json.load(f)\n",
    "                print(f\"   📖 Loaded existing playlists database with {len(existing_playlists_db.get('playlists', {}))} playlists\")\n",
    "            except Exception as e:\n",
    "                print(f\"   ⚠️  Warning: Could not load existing playlists database: {e}\")\n",
    "        \n",
    "        # Merge all playlists (existing + current)\n",
    "        all_playlists = existing_playlists_db.get('playlists', {}).copy()\n",
    "        \n",
    "        # Add/update playlists from current session and add song lists\n",
    "        for playlist_name, playlist_info in self.playlist_data.items():\n",
    "            updated_playlist_info = playlist_info.copy()\n",
    "            \n",
    "            # Add songs in this playlist\n",
    "            playlist_songs = []\n",
    "            for song_id, playlists in self.song_to_playlists.items():\n",
    "                if playlist_name in playlists:\n",
    "                    playlist_songs.append(song_id)\n",
    "            \n",
    "            updated_playlist_info['songs'] = playlist_songs\n",
    "            updated_playlist_info['unique_song_count'] = len(playlist_songs)\n",
    "            all_playlists[playlist_name] = updated_playlist_info\n",
    "        \n",
    "        # Save playlists database\n",
    "        playlists_db = {\n",
    "            'playlists': all_playlists,\n",
    "            'stats': {\n",
    "                'total_playlists': len(all_playlists),\n",
    "                'generated_at': datetime.now().isoformat(),\n",
    "                'last_session_stats': self.stats.copy()\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        with open(playlists_db_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(playlists_db, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"   ✅ Saved playlists database with {len(all_playlists)} total playlists\")\n",
    "        \n",
    "        # 3. SONG-PLAYLIST MAPPING - Load existing and merge\n",
    "        mapping_db_path = self.metadata_output / 'song_playlist_mapping.json'\n",
    "        existing_mapping_db = {'song_to_playlists': {}, 'stats': {}}\n",
    "        \n",
    "        if mapping_db_path.exists():\n",
    "            try:\n",
    "                with open(mapping_db_path, 'r', encoding='utf-8') as f:\n",
    "                    existing_mapping_db = json.load(f)\n",
    "                print(f\"   📖 Loaded existing mapping database with {len(existing_mapping_db.get('song_to_playlists', {}))} mappings\")\n",
    "            except Exception as e:\n",
    "                print(f\"   ⚠️  Warning: Could not load existing mapping database: {e}\")\n",
    "        \n",
    "        # Merge all mappings (existing + current)\n",
    "        all_mappings = existing_mapping_db.get('song_to_playlists', {}).copy()\n",
    "        \n",
    "        # Add/update mappings from current session\n",
    "        for song_id, playlists in self.song_to_playlists.items():\n",
    "            all_mappings[song_id] = playlists.copy()\n",
    "        \n",
    "        # Save mapping database\n",
    "        mapping_db = {\n",
    "            'song_to_playlists': all_mappings,\n",
    "            'stats': {\n",
    "                'total_mappings': len(all_mappings),\n",
    "                'generated_at': datetime.now().isoformat(),\n",
    "                'last_session_stats': self.stats.copy()\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        with open(mapping_db_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(mapping_db, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"   ✅ Saved mapping database with {len(all_mappings)} total mappings\")\n",
    "        print(\"✅ All metadata saved successfully!\")\n",
    "    \n",
    "    def run(self, cleanup_orphans: bool = True):\n",
    "        \"\"\"Run the incremental consolidation process\"\"\"\n",
    "        print(\"🎵 Starting incremental consolidation process...\")\n",
    "        print(f\"📁 Base folder: {self.base_songs_folder}\")\n",
    "        print(f\"📁 Output folder: {self.output_folder}\")\n",
    "        \n",
    "        if not self.base_songs_folder.exists():\n",
    "            print(f\"❌ Error: Base songs folder '{self.base_songs_folder}' does not exist!\")\n",
    "            return\n",
    "        \n",
    "        # Process each playlist folder\n",
    "        playlist_folders = [f for f in self.base_songs_folder.iterdir() if f.is_dir()]\n",
    "        \n",
    "        if not playlist_folders:\n",
    "            print(\"❌ No playlist folders found!\")\n",
    "            return\n",
    "        \n",
    "        print(f\"📂 Found {len(playlist_folders)} playlist folders\")\n",
    "        \n",
    "        for playlist_folder in playlist_folders:\n",
    "            self.process_playlist_folder(playlist_folder)\n",
    "        \n",
    "        # Clean up orphaned data if requested\n",
    "        if cleanup_orphans:\n",
    "            self.cleanup_orphaned_data()\n",
    "        \n",
    "        # Save all metadata\n",
    "        self.save_metadata()\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"🎉 INCREMENTAL CONSOLIDATION COMPLETE\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"🎵 Total unique songs: {len(self.unique_songs)}\")\n",
    "        print(f\"📋 Total playlists: {len(self.playlist_data)}\")\n",
    "        print(f\"📁 Songs folder: {self.songs_output}\")\n",
    "        print(f\"📁 Metadata folder: {self.metadata_output}\")\n",
    "        \n",
    "        print(\"\\n📊 Session Statistics:\")\n",
    "        print(f\"   • Existing songs found: {self.stats['existing_songs_found']}\")\n",
    "        print(f\"   • New songs added: {self.stats['new_songs_added']}\")\n",
    "        print(f\"   • New playlists added: {self.stats['new_playlists_added']}\")\n",
    "        print(f\"   • Playlists updated: {self.stats['playlists_updated']}\")\n",
    "        print(f\"   • Duplicates skipped: {self.stats['duplicates_skipped']}\")\n",
    "        print(f\"   • Songs added to existing playlists: {self.stats['songs_added_to_existing_playlists']}\")\n",
    "        \n",
    "        print(\"\\n📄 Generated/Updated files:\")\n",
    "        print(\"   • songs_database.json (complete song information)\")\n",
    "        print(\"   • playlists_database.json (playlist information with song lists)\")\n",
    "        print(\"   • song_playlist_mapping.json (song to playlist relationships)\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Configuration\n",
    "    SONGS_FOLDER = \"songs\"  # Your base songs folder\n",
    "    OUTPUT_FOLDER = \"consolidated_music\"  # Output folder name\n",
    "    \n",
    "    # Create and run consolidator\n",
    "    consolidator = IncrementalSongConsolidator(SONGS_FOLDER, OUTPUT_FOLDER)\n",
    "    consolidator.run(cleanup_orphans=True)  # Set to False if you don't want to remove orphaned data\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
