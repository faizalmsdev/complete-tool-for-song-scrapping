{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b344168",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import threading\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "import sys\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from seleniumwire import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import gzip\n",
    "import brotli\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "class Config:\n",
    "    # Spotify settings\n",
    "    SPOTIFY_URL = \"\"  # Will be set by user input\n",
    "    TARGET_API_URL = \"https://api-partner.spotify.com/pathfinder/v2/query\"\n",
    "    \n",
    "    # Scrolling settings\n",
    "    SCROLL_PAUSE_TIME = 2\n",
    "    AUTO_SCROLL_ENABLED = True\n",
    "    SCROLL_PIXELS = 800\n",
    "    \n",
    "    # Download settings\n",
    "    AUDIO_QUALITY = '192K'\n",
    "    MAX_RETRIES = 3\n",
    "    DOWNLOAD_DELAY = 1  # Seconds between downloads\n",
    "    \n",
    "    # Metadata settings\n",
    "    DOWNLOAD_COVER_ART = True\n",
    "    COVER_ART_SIZE = 640  # Preferred size (640x640, 300x300, or 64x64)\n",
    "    \n",
    "    # Error handling settings\n",
    "    SKIP_INVALID_TRACKS = True\n",
    "    MIN_TRACK_NAME_LENGTH = 1\n",
    "    MIN_ARTIST_NAME_LENGTH = 1\n",
    "    \n",
    "    # YouTube bot prevention settings - UPDATED\n",
    "    USE_COOKIES_FROM_BROWSER = False  # CHANGED: Disable browser cookies\n",
    "    BROWSER_FOR_COOKIES = \"chrome\"  # Options: chrome, firefox, edge, safari\n",
    "    USE_PROXY = False\n",
    "    PROXY_URL = \"\"\n",
    "    RANDOM_USER_AGENT = True\n",
    "    EXTRA_DELAY_ON_ERROR = 10\n",
    "    ALLOW_YOUTUBE_CAPTCHA = True\n",
    "# === GLOBAL VARIABLES ===\n",
    "captured_data = []\n",
    "all_playlist_items = []\n",
    "seen_requests = set()\n",
    "stop_capture = False\n",
    "auto_scroll_active = False\n",
    "\n",
    "# === ERROR HANDLING UTILITIES ===\n",
    "def safe_get(data, *keys, default=\"Unknown\"):\n",
    "    \"\"\"Safely navigate nested dictionaries with fallback\"\"\"\n",
    "    try:\n",
    "        result = data\n",
    "        for key in keys:\n",
    "            if isinstance(result, dict) and key in result:\n",
    "                result = result[key]\n",
    "            else:\n",
    "                return default\n",
    "        return result if result is not None and str(result).strip() else default\n",
    "    except:\n",
    "        return default\n",
    "\n",
    "def validate_track_data(track_info):\n",
    "    \"\"\"Validate if track data is sufficient for processing\"\"\"\n",
    "    track_name = track_info.get('track_name', '').strip()\n",
    "    artists_string = track_info.get('artists_string', '').strip()\n",
    "    \n",
    "    # Check if essential fields are present and valid\n",
    "    if not track_name or len(track_name) < Config.MIN_TRACK_NAME_LENGTH:\n",
    "        return False, \"Track name is empty or too short\"\n",
    "    \n",
    "    if not artists_string or len(artists_string) < Config.MIN_ARTIST_NAME_LENGTH:\n",
    "        return False, \"Artist name is empty or too short\"\n",
    "    \n",
    "    if track_name.lower() in ['unknown track', 'unknown', '']:\n",
    "        return False, \"Track name is placeholder value\"\n",
    "    \n",
    "    if artists_string.lower() in ['unknown artist', 'unknown', '']:\n",
    "        return False, \"Artist name is placeholder value\"\n",
    "    \n",
    "    return True, \"Valid\"\n",
    "\n",
    "def get_random_user_agent():\n",
    "    \"\"\"Return a random user agent to avoid detection\"\"\"\n",
    "    user_agents = [\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36\",\n",
    "        \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n",
    "        \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/121.0\",\n",
    "        \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:109.0) Gecko/20100101 Firefox/121.0\"\n",
    "    ]\n",
    "    import random\n",
    "    return random.choice(user_agents)\n",
    "\n",
    "def log_skipped_track(track_info, reason, log_file):\n",
    "    \"\"\"Log information about skipped tracks\"\"\"\n",
    "    try:\n",
    "        with open(log_file, 'a', encoding='utf-8') as f:\n",
    "            f.write(f\"SKIPPED TRACK:\\n\")\n",
    "            f.write(f\"  Reason: {reason}\\n\")\n",
    "            f.write(f\"  Track Name: '{track_info.get('track_name', 'N/A')}'\\n\")\n",
    "            f.write(f\"  Artists: '{track_info.get('artists_string', 'N/A')}'\\n\")\n",
    "            f.write(f\"  Album: '{track_info.get('album_name', 'N/A')}'\\n\")\n",
    "            f.write(f\"  URI: '{track_info.get('track_uri', 'N/A')}'\\n\")\n",
    "            f.write(f\"  Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "            f.write(\"-\" * 50 + \"\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è  Failed to log skipped track: {e}\")\n",
    "\n",
    "# === UTILITY FUNCTIONS ===\n",
    "def install_required_packages():\n",
    "    \"\"\"Install required packages if not available\"\"\"\n",
    "    try:\n",
    "        import yt_dlp\n",
    "        print(\"‚úÖ yt-dlp is available\")\n",
    "    except ImportError:\n",
    "        print(\"üì¶ Installing yt-dlp...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"yt-dlp\"])\n",
    "        print(\"‚úÖ yt-dlp installed successfully\")\n",
    "    \n",
    "    try:\n",
    "        import requests\n",
    "        print(\"‚úÖ requests is available\")\n",
    "    except ImportError:\n",
    "        print(\"üì¶ Installing requests...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"requests\"])\n",
    "        print(\"‚úÖ requests installed successfully\")\n",
    "\n",
    "def check_prerequisites():\n",
    "    \"\"\"Check if required tools are available\"\"\"\n",
    "    print(\"üîß Checking prerequisites...\")\n",
    "    \n",
    "    # Check ffmpeg\n",
    "    try:\n",
    "        result = subprocess.run(['ffmpeg', '-version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            print(\"   ‚úÖ ffmpeg found\")\n",
    "        else:\n",
    "            print(\"   ‚ùå ffmpeg not working properly\")\n",
    "            return False\n",
    "    except FileNotFoundError:\n",
    "        print(\"   ‚ùå ffmpeg not found - please install ffmpeg\")\n",
    "        print(\"      Download from: https://ffmpeg.org/download.html\")\n",
    "        return False\n",
    "    \n",
    "    install_required_packages()\n",
    "    return True\n",
    "\n",
    "def sanitize_filename(filename):\n",
    "    \"\"\"Remove invalid characters from filename with enhanced error handling\"\"\"\n",
    "    try:\n",
    "        if not filename or not str(filename).strip():\n",
    "            return \"unknown_file\"\n",
    "        \n",
    "        filename = str(filename).strip()\n",
    "        filename = re.sub(r'[<>:\"/\\\\|?*]', '', filename)\n",
    "        filename = re.sub(r'[^\\w\\s-]', '', filename)\n",
    "        filename = re.sub(r'[-\\s]+', '-', filename)\n",
    "        result = filename.strip('-')[:100]\n",
    "        \n",
    "        # Ensure we have a valid filename\n",
    "        return result if result else \"unknown_file\"\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è  Error sanitizing filename '{filename}': {e}\")\n",
    "        return \"unknown_file\"\n",
    "\n",
    "def download_cover_art(cover_url, output_path):\n",
    "    \"\"\"Download cover art image with enhanced error handling\"\"\"\n",
    "    try:\n",
    "        if not cover_url or not str(cover_url).strip():\n",
    "            return False\n",
    "            \n",
    "        response = requests.get(cover_url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        with open(output_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è  Failed to download cover art: {e}\")\n",
    "        return False\n",
    "\n",
    "def get_best_cover_art_url(cover_sources, preferred_size=640):\n",
    "    \"\"\"Get the best cover art URL from sources with error handling\"\"\"\n",
    "    try:\n",
    "        if not cover_sources or not isinstance(cover_sources, list):\n",
    "            return None\n",
    "        \n",
    "        # Try to find preferred size\n",
    "        for source in cover_sources:\n",
    "            if isinstance(source, dict) and source.get('width') == preferred_size:\n",
    "                url = source.get('url')\n",
    "                if url:\n",
    "                    return url\n",
    "        \n",
    "        # If preferred size not found, get the largest available\n",
    "        valid_sources = [s for s in cover_sources if isinstance(s, dict) and s.get('width') and s.get('url')]\n",
    "        if valid_sources:\n",
    "            largest = max(valid_sources, key=lambda x: x.get('width', 0))\n",
    "            return largest.get('url')\n",
    "        \n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è  Error getting cover art URL: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_enhanced_ydl_opts(output_path):\n",
    "    \"\"\"Get enhanced yt-dlp options with proper cookie handling\"\"\"\n",
    "    opts = {\n",
    "        'format': 'bestaudio/best',\n",
    "        'extractaudio': True,\n",
    "        'audioformat': 'mp3',\n",
    "        'audioquality': Config.AUDIO_QUALITY,\n",
    "        'outtmpl': output_path,\n",
    "        'noplaylist': True,\n",
    "        'quiet': False,\n",
    "        'no_warnings': False,\n",
    "        'default_search': 'ytsearch1:',\n",
    "        'postprocessors': [{\n",
    "            'key': 'FFmpegExtractAudio',\n",
    "            'preferredcodec': 'mp3',\n",
    "            'preferredquality': '192',\n",
    "        }],\n",
    "        # Enhanced bot prevention options\n",
    "        'extractor_retries': 5,\n",
    "        'fragment_retries': 5,\n",
    "        'retries': 5,\n",
    "        'sleep_interval': 3,\n",
    "        'max_sleep_interval': 15,\n",
    "        'sleep_interval_requests': 3,\n",
    "        'sleep_interval_subtitles': 3,\n",
    "        # Additional anti-bot measures\n",
    "        'http_chunk_size': 10485760,  # 10MB chunks\n",
    "        'ratelimit': 1000000,  # 1MB/s rate limit to appear more human-like\n",
    "    }\n",
    "    \n",
    "    # Add random user agent\n",
    "    if Config.RANDOM_USER_AGENT:\n",
    "        opts['http_headers'] = {\n",
    "            'User-Agent': get_random_user_agent(),\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "            'Accept-Language': 'en-us,en;q=0.5',\n",
    "            'Accept-Encoding': 'gzip,deflate',\n",
    "            'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.7',\n",
    "            'Keep-Alive': '300',\n",
    "            'Connection': 'keep-alive',\n",
    "        }\n",
    "    \n",
    "    # FIXED: Prioritize cookies.txt file over browser cookies\n",
    "    cookies_file = \"cookies.txt\"\n",
    "    if os.path.exists(cookies_file):\n",
    "        opts['cookiefile'] = cookies_file\n",
    "        print(f\"   üç™ Using cookies.txt file\")\n",
    "    elif Config.USE_COOKIES_FROM_BROWSER:\n",
    "        try:\n",
    "            opts['cookiesfrombrowser'] = (Config.BROWSER_FOR_COOKIES,)\n",
    "            print(f\"   üç™ Using cookies from {Config.BROWSER_FOR_COOKIES} browser\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è  Could not load browser cookies: {e}\")\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è  No cookies available - may encounter bot detection\")\n",
    "    \n",
    "    # Add proxy if configured\n",
    "    if Config.USE_PROXY and Config.PROXY_URL:\n",
    "        opts['proxy'] = Config.PROXY_URL\n",
    "        print(f\"   üåê Using proxy: {Config.PROXY_URL}\")\n",
    "    \n",
    "    return opts\n",
    "def handle_youtube_captcha():\n",
    "    \"\"\"Handle YouTube CAPTCHA by opening browser\"\"\"\n",
    "    if Config.ALLOW_YOUTUBE_CAPTCHA:\n",
    "        print(\"\\nü§ñ YouTube may require CAPTCHA verification.\")\n",
    "        print(\"   Opening YouTube in browser for manual verification...\")\n",
    "        \n",
    "        try:\n",
    "            import webbrowser\n",
    "            webbrowser.open(\"https://www.youtube.com\")\n",
    "            print(\"   ‚úÖ YouTube opened in browser\")\n",
    "            print(\"   üëÜ Please solve any CAPTCHA if prompted, then press Enter to continue\")\n",
    "            input(\"   Press Enter when ready...\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è  Could not open browser: {e}\")\n",
    "            return False\n",
    "    return False\n",
    "\n",
    "# === SPOTIFY CAPTURE FUNCTIONS ===\n",
    "def decode_response_body(response):\n",
    "    \"\"\"Decode response body handling different compression formats\"\"\"\n",
    "    try:\n",
    "        body = response.body\n",
    "        if not body:\n",
    "            return \"\"\n",
    "        \n",
    "        encoding = response.headers.get('content-encoding', '').lower()\n",
    "        \n",
    "        if encoding == 'gzip':\n",
    "            body = gzip.decompress(body)\n",
    "        elif encoding == 'br':\n",
    "            body = brotli.decompress(body)\n",
    "        elif encoding == 'deflate':\n",
    "            import zlib\n",
    "            body = zlib.decompress(body)\n",
    "        \n",
    "        try:\n",
    "            return body.decode('utf-8')\n",
    "        except UnicodeDecodeError:\n",
    "            return body.decode('utf-8', errors='ignore')\n",
    "    except Exception as e:\n",
    "        print(f\"[!] Error decoding response body: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def parse_json_response(body_text):\n",
    "    \"\"\"Try to parse response as JSON\"\"\"\n",
    "    try:\n",
    "        return json.loads(body_text)\n",
    "    except json.JSONDecodeError:\n",
    "        return body_text\n",
    "\n",
    "def is_playlist_items_response(parsed_response):\n",
    "    \"\"\"Check if the response contains playlist items data\"\"\"\n",
    "    try:\n",
    "        if isinstance(parsed_response, dict):\n",
    "            data = parsed_response.get('data', {})\n",
    "            playlist_v2 = data.get('playlistV2', {})\n",
    "            content = playlist_v2.get('content', {})\n",
    "            return content.get('__typename') == 'PlaylistItemsPage'\n",
    "        return False\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def extract_items_from_response(parsed_response):\n",
    "    \"\"\"Extract the items array from playlist response\"\"\"\n",
    "    try:\n",
    "        if isinstance(parsed_response, dict):\n",
    "            data = parsed_response.get('data', {})\n",
    "            playlist_v2 = data.get('playlistV2', {})\n",
    "            content = playlist_v2.get('content', {})\n",
    "            items = content.get('items', [])\n",
    "            return items\n",
    "    except:\n",
    "        pass\n",
    "    return []\n",
    "\n",
    "def extract_pagination_info(parsed_response):\n",
    "    \"\"\"Extract pagination information from the response\"\"\"\n",
    "    try:\n",
    "        if isinstance(parsed_response, dict):\n",
    "            data = parsed_response.get('data', {})\n",
    "            playlist_v2 = data.get('playlistV2', {})\n",
    "            content = playlist_v2.get('content', {})\n",
    "            paging_info = content.get('pagingInfo', {})\n",
    "            items = content.get('items', [])\n",
    "            \n",
    "            return {\n",
    "                'limit': paging_info.get('limit', 0),\n",
    "                'offset': paging_info.get('offset', 0),\n",
    "                'totalCount': paging_info.get('totalCount', 0),\n",
    "                'items_in_response': len(items)\n",
    "            }\n",
    "    except:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def auto_scroll(driver):\n",
    "    \"\"\"Auto-scroll the page to load all playlist items\"\"\"\n",
    "    global stop_capture, auto_scroll_active\n",
    "    auto_scroll_active = True\n",
    "    scroll_count = 0\n",
    "    \n",
    "    print(\"üîÑ Starting auto-scroll...\")\n",
    "    \n",
    "    try:\n",
    "        time.sleep(3)\n",
    "        \n",
    "        while not stop_capture and Config.AUTO_SCROLL_ENABLED:\n",
    "            try:\n",
    "                current_scroll = driver.execute_script(\"return window.pageYOffset;\")\n",
    "                page_height = driver.execute_script(\"return document.body.scrollHeight;\")\n",
    "                window_height = driver.execute_script(\"return window.innerHeight;\")\n",
    "                \n",
    "                driver.execute_script(f\"window.scrollBy(0, {Config.SCROLL_PIXELS});\")\n",
    "                scroll_count += 1\n",
    "                \n",
    "                print(f\"üîΩ Scroll #{scroll_count} - Position: {current_scroll}px\")\n",
    "                \n",
    "                time.sleep(Config.SCROLL_PAUSE_TIME)\n",
    "                \n",
    "                new_scroll = driver.execute_script(\"return window.pageYOffset;\")\n",
    "                if new_scroll == current_scroll or new_scroll + window_height >= page_height:\n",
    "                    print(\"üìç Reached bottom of page, continuing to monitor...\")\n",
    "                    time.sleep(Config.SCROLL_PAUSE_TIME * 2)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"[!] Error during scrolling: {e}\")\n",
    "                time.sleep(Config.SCROLL_PAUSE_TIME)\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"[!] Error in auto-scroll thread: {e}\")\n",
    "    \n",
    "    auto_scroll_active = False\n",
    "\n",
    "def capture_requests(driver):\n",
    "    \"\"\"Capture playlist requests from Spotify\"\"\"\n",
    "    global stop_capture, all_playlist_items\n",
    "    playlist_items_count = 0\n",
    "    \n",
    "    while not stop_capture:\n",
    "        for request in driver.requests:\n",
    "            if (request.response and \n",
    "                request.id not in seen_requests and \n",
    "                Config.TARGET_API_URL in request.url):\n",
    "                \n",
    "                seen_requests.add(request.id)\n",
    "                \n",
    "                try:\n",
    "                    response_body = decode_response_body(request.response)\n",
    "                    parsed_response = parse_json_response(response_body)\n",
    "                    \n",
    "                    if is_playlist_items_response(parsed_response):\n",
    "                        playlist_items_count += 1\n",
    "                        pagination_info = extract_pagination_info(parsed_response)\n",
    "                        items_in_response = extract_items_from_response(parsed_response)\n",
    "                        \n",
    "                        print(f\"üéØ Captured Playlist Items Request #{playlist_items_count}\")\n",
    "                        print(f\"   URL: {request.url}\")\n",
    "                        print(f\"   Status: {request.response.status_code}\")\n",
    "                        \n",
    "                        if pagination_info:\n",
    "                            print(f\"   üìÑ Pagination: Offset {pagination_info['offset']}, \"\n",
    "                                  f\"Limit {pagination_info['limit']}, \"\n",
    "                                  f\"Items: {pagination_info['items_in_response']}, \"\n",
    "                                  f\"Total: {pagination_info['totalCount']}\")\n",
    "                        \n",
    "                        print(f\"   üéµ Items extracted: {len(items_in_response)}\")\n",
    "                        \n",
    "                        if items_in_response:\n",
    "                            all_playlist_items.extend(items_in_response)\n",
    "                            print(f\"   üìö Total items collected: {len(all_playlist_items)}\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"[!] Error processing request: {e}\")\n",
    "        \n",
    "        time.sleep(0.5)\n",
    "\n",
    "def listen_for_commands():\n",
    "    \"\"\"Listen for user commands during capture\"\"\"\n",
    "    global stop_capture, Config\n",
    "    while True:\n",
    "        print(\"\\nCommands:\")\n",
    "        print(\"  'stop' - Stop capturing and proceed to processing\")\n",
    "        print(\"  'scroll on' - Enable auto-scrolling\")\n",
    "        print(\"  'scroll off' - Disable auto-scrolling\")\n",
    "        print(\"  'status' - Show current status\")\n",
    "        print(\"  'items' - Show total items collected\")\n",
    "        \n",
    "        user_input = input(\">>> \").strip().lower()\n",
    "        \n",
    "        if user_input == \"stop\":\n",
    "            stop_capture = True\n",
    "            break\n",
    "        elif user_input == \"scroll on\":\n",
    "            Config.AUTO_SCROLL_ENABLED = True\n",
    "            print(\"‚úÖ Auto-scrolling enabled\")\n",
    "        elif user_input == \"scroll off\":\n",
    "            Config.AUTO_SCROLL_ENABLED = False\n",
    "            print(\"üõë Auto-scrolling disabled\")\n",
    "        elif user_input == \"status\":\n",
    "            print(f\"üìä Status:\")\n",
    "            print(f\"   Total items collected: {len(all_playlist_items)}\")\n",
    "            print(f\"   Auto-scroll: {'ON' if Config.AUTO_SCROLL_ENABLED else 'OFF'}\")\n",
    "            print(f\"   Auto-scroll active: {'YES' if auto_scroll_active else 'NO'}\")\n",
    "        elif user_input == \"items\":\n",
    "            print(f\"üìö Total items collected: {len(all_playlist_items)}\")\n",
    "            if all_playlist_items:\n",
    "                print(f\"   Latest item example keys: {list(all_playlist_items[-1].keys()) if all_playlist_items[-1] else 'None'}\")\n",
    "\n",
    "# === ENHANCED TRACK EXTRACTION FUNCTIONS ===\n",
    "def extract_enhanced_track_info(items, cover_art_folder):\n",
    "    \"\"\"Extract comprehensive track information with robust error handling\"\"\"\n",
    "    tracks_info = []\n",
    "    skipped_count = 0\n",
    "    error_count = 0\n",
    "    \n",
    "    print(f\"üéµ Processing {len(items)} items with enhanced metadata and error handling...\")\n",
    "    \n",
    "    # Create skipped tracks log file\n",
    "    skipped_log_file = os.path.join(os.path.dirname(cover_art_folder), \"skipped_tracks.log\")\n",
    "    \n",
    "    for i, item in enumerate(items, 1):\n",
    "        try:\n",
    "            # Safety check for item structure\n",
    "            if not isinstance(item, dict):\n",
    "                skipped_count += 1\n",
    "                print(f\"   ‚è≠Ô∏è  [{i}] Skipped: Invalid item structure\")\n",
    "                continue\n",
    "            \n",
    "            item_v2 = safe_get(item, 'itemV2', default={})\n",
    "            \n",
    "            # Check if it's a track\n",
    "            if safe_get(item_v2, '__typename') != 'TrackResponseWrapper':\n",
    "                skipped_count += 1\n",
    "                continue\n",
    "                \n",
    "            track_data = safe_get(item_v2, 'data', default={})\n",
    "            \n",
    "            # Basic track info with safe extraction\n",
    "            track_name = safe_get(track_data, 'name', default='').strip()\n",
    "            track_uri = safe_get(track_data, 'uri', default='')\n",
    "            \n",
    "            # Artists info with safe extraction\n",
    "            artists_data = safe_get(track_data, 'artists', 'items', default=[])\n",
    "            artist_names = []\n",
    "            artist_uris = []\n",
    "            \n",
    "            if isinstance(artists_data, list):\n",
    "                for artist in artists_data:\n",
    "                    if isinstance(artist, dict):\n",
    "                        artist_name = safe_get(artist, 'profile', 'name', default='').strip()\n",
    "                        if artist_name and artist_name not in artist_names:\n",
    "                            artist_names.append(artist_name)\n",
    "                            artist_uris.append(safe_get(artist, 'uri', default=''))\n",
    "            \n",
    "            # Create artists string\n",
    "            artists_string = ', '.join(artist_names) if artist_names else 'Unknown Artist'\n",
    "            \n",
    "            # Album info with safe extraction\n",
    "            album_data = safe_get(track_data, 'albumOfTrack', default={})\n",
    "            album_name = safe_get(album_data, 'name', default='Unknown Album').strip()\n",
    "            album_uri = safe_get(album_data, 'uri', default='')\n",
    "            \n",
    "            # Create preliminary track info for validation\n",
    "            preliminary_track_info = {\n",
    "                'track_name': track_name,\n",
    "                'artists_string': artists_string,\n",
    "                'album_name': album_name,\n",
    "                'track_uri': track_uri\n",
    "            }\n",
    "            \n",
    "            # Validate track data\n",
    "            is_valid, validation_reason = validate_track_data(preliminary_track_info)\n",
    "            \n",
    "            if not is_valid and Config.SKIP_INVALID_TRACKS:\n",
    "                skipped_count += 1\n",
    "                print(f\"   ‚è≠Ô∏è  [{i}] Skipped: {validation_reason}\")\n",
    "                print(f\"      Track: '{track_name}' by '{artists_string}'\")\n",
    "                log_skipped_track(preliminary_track_info, validation_reason, skipped_log_file)\n",
    "                continue\n",
    "            \n",
    "            # Cover art info with safe extraction\n",
    "            cover_sources = safe_get(album_data, 'coverArt', 'sources', default=[])\n",
    "            cover_url = get_best_cover_art_url(cover_sources, Config.COVER_ART_SIZE)\n",
    "            cover_filename = None\n",
    "            \n",
    "            # Download cover art if available\n",
    "            if cover_url and Config.DOWNLOAD_COVER_ART:\n",
    "                try:\n",
    "                    safe_track_name = sanitize_filename(f\"{track_name}_{artist_names[0] if artist_names else 'unknown'}\")\n",
    "                    cover_filename = f\"{safe_track_name}_cover.jpg\"\n",
    "                    cover_path = os.path.join(cover_art_folder, cover_filename)\n",
    "                    \n",
    "                    if download_cover_art(cover_url, cover_path):\n",
    "                        print(f\"   üñºÔ∏è  Downloaded cover art: {cover_filename}\")\n",
    "                    else:\n",
    "                        cover_filename = None\n",
    "                except Exception as e:\n",
    "                    print(f\"   ‚ö†Ô∏è  Cover art download failed: {e}\")\n",
    "                    cover_filename = None\n",
    "            \n",
    "            # Track duration with safe extraction\n",
    "            duration_ms = safe_get(track_data, 'trackDuration', 'totalMilliseconds', default=0)\n",
    "            try:\n",
    "                duration_ms = int(duration_ms) if duration_ms else 0\n",
    "            except (ValueError, TypeError):\n",
    "                duration_ms = 0\n",
    "            \n",
    "            duration_seconds = duration_ms / 1000 if duration_ms else 0\n",
    "            \n",
    "            # Additional metadata with safe extraction\n",
    "            track_number = safe_get(track_data, 'trackNumber', default=0)\n",
    "            disc_number = safe_get(track_data, 'discNumber', default=1)\n",
    "            playcount = safe_get(track_data, 'playcount', default='0')\n",
    "            content_rating = safe_get(track_data, 'contentRating', 'label', default='NONE')\n",
    "            \n",
    "            # Added info with safe extraction\n",
    "            added_at = safe_get(item, 'addedAt', 'isoString', default='')\n",
    "            added_by_data = safe_get(item, 'addedBy', 'data', default={})\n",
    "            added_by_name = safe_get(added_by_data, 'name', default='Unknown')\n",
    "            added_by_username = safe_get(added_by_data, 'username', default='')\n",
    "            \n",
    "            # Added by avatar\n",
    "            added_by_avatar_sources = safe_get(added_by_data, 'avatar', 'sources', default=[])\n",
    "            added_by_avatar_url = get_best_cover_art_url(added_by_avatar_sources, 300)\n",
    "            \n",
    "            # Format added date safely\n",
    "            added_at_formatted = ''\n",
    "            if added_at:\n",
    "                try:\n",
    "                    added_at_formatted = datetime.fromisoformat(added_at.replace('Z', '+00:00')).strftime('%Y-%m-%d %H:%M:%S')\n",
    "                except Exception as e:\n",
    "                    print(f\"   ‚ö†Ô∏è  Date formatting failed: {e}\")\n",
    "                    added_at_formatted = added_at\n",
    "            \n",
    "            # Create final track info\n",
    "            track_info = {\n",
    "                # Basic info\n",
    "                'track_name': track_name,\n",
    "                'track_uri': track_uri,\n",
    "                'artists': artist_names,\n",
    "                'artist_uris': artist_uris,\n",
    "                'artists_string': artists_string,\n",
    "                \n",
    "                # Album info\n",
    "                'album_name': album_name,\n",
    "                'album_uri': album_uri,\n",
    "                \n",
    "                # Cover art\n",
    "                'cover_art_url': cover_url,\n",
    "                'cover_art_filename': cover_filename,\n",
    "                'cover_art_sources': cover_sources,\n",
    "                \n",
    "                # Duration and track info\n",
    "                'duration_ms': duration_ms,\n",
    "                'duration_seconds': duration_seconds,\n",
    "                'duration_formatted': f\"{int(duration_seconds//60)}:{int(duration_seconds%60):02d}\" if duration_seconds else \"0:00\",\n",
    "                'track_number': track_number,\n",
    "                'disc_number': disc_number,\n",
    "                \n",
    "                # Metadata\n",
    "                'playcount': playcount,\n",
    "                'content_rating': content_rating,\n",
    "                \n",
    "                # Added info\n",
    "                'added_at': added_at,\n",
    "                'added_at_formatted': added_at_formatted,\n",
    "                'added_by_name': added_by_name,\n",
    "                'added_by_username': added_by_username,\n",
    "                'added_by_avatar_url': added_by_avatar_url,\n",
    "                \n",
    "                # Processing info\n",
    "                'processed_at': datetime.now().isoformat(),\n",
    "            }\n",
    "            \n",
    "            tracks_info.append(track_info)\n",
    "            \n",
    "            # Show progress every 50 items or for problematic items\n",
    "            if i % 50 == 0 or not is_valid:\n",
    "                print(f\"‚úÖ Processed {i}/{len(items)} items... (Valid tracks: {len(tracks_info)})\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            error_count += 1\n",
    "            print(f\"‚ö†Ô∏è  Error processing item {i}: {e}\")\n",
    "            \n",
    "            # Log the error with available information\n",
    "            try:\n",
    "                error_info = {\n",
    "                    'track_name': 'ERROR_PROCESSING',\n",
    "                    'artists_string': 'ERROR_PROCESSING',\n",
    "                    'album_name': 'ERROR_PROCESSING',\n",
    "                    'track_uri': '',\n",
    "                    'error': str(e)\n",
    "                }\n",
    "                log_skipped_track(error_info, f\"Processing error: {str(e)}\", skipped_log_file)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            continue\n",
    "    \n",
    "    print(f\"‚úÖ Successfully extracted {len(tracks_info)} valid tracks with metadata\")\n",
    "    if skipped_count > 0:\n",
    "        print(f\"‚è≠Ô∏è  Skipped {skipped_count} invalid/problematic items\")\n",
    "    if error_count > 0:\n",
    "        print(f\"‚ö†Ô∏è  {error_count} items had processing errors\")\n",
    "    \n",
    "    if skipped_count > 0 or error_count > 0:\n",
    "        print(f\"üìã Detailed skip log saved to: {skipped_log_file}\")\n",
    "    \n",
    "    return tracks_info\n",
    "\n",
    "# === ENHANCED DOWNLOAD FUNCTIONS ===\n",
    "def search_and_download_audio(track_info, output_folder):\n",
    "    \"\"\"Search for and download audio with enhanced bot prevention\"\"\"\n",
    "    import yt_dlp\n",
    "    \n",
    "    try:\n",
    "        track_name = track_info.get('track_name', 'Unknown')\n",
    "        artists_str = track_info.get('artists_string', 'Unknown')\n",
    "        \n",
    "        # Validate track info before attempting download\n",
    "        is_valid, reason = validate_track_data(track_info)\n",
    "        if not is_valid:\n",
    "            return {\n",
    "                'track_name': track_name,\n",
    "                'artists': artists_str,\n",
    "                'search_query': '',\n",
    "                'status': 'skipped',\n",
    "                'error': f'Invalid track data: {reason}',\n",
    "                'filename': None,\n",
    "                'video_title': None,\n",
    "                'metadata': track_info\n",
    "            }\n",
    "        \n",
    "        search_query = f\"{track_name} {artists_str}\".strip()\n",
    "        safe_filename = sanitize_filename(f\"{track_name} - {artists_str}\")\n",
    "        \n",
    "        if not safe_filename or safe_filename == \"unknown_file\":\n",
    "            return {\n",
    "                'track_name': track_name,\n",
    "                'artists': artists_str,\n",
    "                'search_query': search_query,\n",
    "                'status': 'failed',\n",
    "                'error': 'Could not create valid filename',\n",
    "                'filename': None,\n",
    "                'video_title': None,\n",
    "                'metadata': track_info\n",
    "            }\n",
    "        \n",
    "        output_path = os.path.join(output_folder, f\"{safe_filename}.%(ext)s\")\n",
    "        \n",
    "        result = {\n",
    "            'track_name': track_name,\n",
    "            'artists': artists_str,\n",
    "            'search_query': search_query,\n",
    "            'status': 'failed',\n",
    "            'error': None,\n",
    "            'filename': None,\n",
    "            'video_title': None,\n",
    "            'metadata': track_info\n",
    "        }\n",
    "        \n",
    "        for attempt in range(Config.MAX_RETRIES):\n",
    "            try:\n",
    "                # Get fresh yt-dlp options for each attempt\n",
    "                ydl_opts = get_enhanced_ydl_opts(output_path)\n",
    "                \n",
    "                with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "                    search_results = ydl.extract_info(\n",
    "                        f\"ytsearch1:{search_query}\",\n",
    "                        download=False\n",
    "                    )\n",
    "                    \n",
    "                    if not search_results or 'entries' not in search_results or not search_results['entries']:\n",
    "                        result['error'] = 'No search results found'\n",
    "                        continue\n",
    "                    \n",
    "                    video_info = search_results['entries'][0]\n",
    "                    result['video_title'] = video_info.get('title', 'Unknown')\n",
    "                    \n",
    "                    ydl.download([video_info['webpage_url']])\n",
    "                    \n",
    "                    expected_filename = f\"{safe_filename}.mp3\"\n",
    "                    full_path = os.path.join(output_folder, expected_filename)\n",
    "                    \n",
    "                    if os.path.exists(full_path):\n",
    "                        result['status'] = 'success'\n",
    "                        result['filename'] = expected_filename\n",
    "                        return result\n",
    "                    else:\n",
    "                        for file in os.listdir(output_folder):\n",
    "                            if file.startswith(safe_filename) and file.endswith('.mp3'):\n",
    "                                result['status'] = 'success'\n",
    "                                result['filename'] = file\n",
    "                                return result\n",
    "                    \n",
    "            except Exception as e:\n",
    "                error_msg = str(e)\n",
    "                result['error'] = error_msg\n",
    "                \n",
    "                # Check if it's a bot detection error\n",
    "                if \"Sign in to confirm you're not a bot\" in error_msg:\n",
    "                    print(f\"   ü§ñ Bot detection triggered on attempt {attempt + 1}\")\n",
    "                    if attempt < Config.MAX_RETRIES - 1:\n",
    "                        print(f\"   ‚è∏Ô∏è  Waiting {Config.EXTRA_DELAY_ON_ERROR} seconds before retry...\")\n",
    "                        time.sleep(Config.EXTRA_DELAY_ON_ERROR)\n",
    "                        \n",
    "                        # Try to handle CAPTCHA\n",
    "                        if Config.ALLOW_YOUTUBE_CAPTCHA and attempt == 0:\n",
    "                            handle_youtube_captcha()\n",
    "                    continue\n",
    "                \n",
    "                if attempt < Config.MAX_RETRIES - 1:\n",
    "                    print(f\"   ‚ö†Ô∏è  Attempt {attempt + 1} failed: {e}, retrying...\")\n",
    "                    time.sleep(2)\n",
    "                continue\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'track_name': track_info.get('track_name', 'Unknown'),\n",
    "            'artists': track_info.get('artists_string', 'Unknown'),\n",
    "            'search_query': '',\n",
    "            'status': 'error',\n",
    "            'error': f'Unexpected error: {str(e)}',\n",
    "            'filename': None,\n",
    "            'video_title': None,\n",
    "            'metadata': track_info\n",
    "        }\n",
    "\n",
    "def create_cookies_txt_guide():\n",
    "    \"\"\"Display guide for creating cookies.txt file\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"COOKIES.TXT SETUP GUIDE\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"To fix YouTube bot detection, you need to provide cookies.\")\n",
    "    print(\"Here are your options:\")\n",
    "    print()\n",
    "    print(\"OPTION 1 - Automatic (Recommended):\")\n",
    "    print(\"1. Make sure Chrome/Firefox is installed\")\n",
    "    print(\"2. Visit YouTube.com in your browser and sign in\")\n",
    "    print(\"3. The script will automatically use your browser cookies\")\n",
    "    print()\n",
    "    print(\"OPTION 2 - Manual cookies.txt:\")\n",
    "    print(\"1. Install 'Get cookies.txt LOCALLY' Chrome extension\")\n",
    "    print(\"2. Visit YouTube.com and sign in\")\n",
    "    print(\"3. Click the extension and export cookies for youtube.com\")\n",
    "    print(\"4. Save the file as 'cookies.txt' in the same folder as this script\")\n",
    "    print()\n",
    "    print(\"OPTION 3 - Using yt-dlp command:\")\n",
    "    print(\"Run this command first to create cookies.txt:\")\n",
    "    print(\"yt-dlp --cookies-from-browser chrome --cookies cookies.txt --skip-download 'https://www.youtube.com/watch?v=dQw4w9WgXcQ'\")\n",
    "    print()\n",
    "    print(\"After setting up cookies, run the script again.\")\n",
    "    print(\"=\"*70)\n",
    "# === MAIN EXECUTION ===\n",
    "def main():\n",
    "    print(\"üéµ Enhanced Spotify Playlist Downloader with Robust Error Handling\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"‚ö†Ô∏è  LEGAL NOTICE: Only download content you have rights to access.\")\n",
    "    print(\"   Respect copyright laws and platform terms of service.\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Check for cookies setup (ADD THIS)\n",
    "    if not os.path.exists(\"cookies.txt\"):\n",
    "        print(\"üç™ No cookies.txt found. For best results against YouTube bot detection:\")\n",
    "        print(\"   The script will try to use your browser cookies automatically.\")\n",
    "        print(\"   If you encounter bot detection errors, you may need to set up cookies.txt\")\n",
    "        \n",
    "        setup_cookies = input(\"\\nWould you like to see the cookies setup guide? (y/N): \").strip().lower()\n",
    "        if setup_cookies == 'y':\n",
    "            create_cookies_txt_guide()\n",
    "            return\n",
    "    else:\n",
    "        print(\"‚úÖ cookies.txt found - using for YouTube authentication\")\n",
    "    \n",
    "    # Check prerequisites\n",
    "    if not check_prerequisites():\n",
    "        print(\"‚ùå Prerequisites not met. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    # Get Spotify playlist URL\n",
    "    Config.SPOTIFY_URL = input(\"\\nEnter Spotify playlist URL: \").strip()\n",
    "    if not Config.SPOTIFY_URL:\n",
    "        print(\"‚ùå No URL provided. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    # Create output folders\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    base_folder = f\"spotify_download_{timestamp}\"\n",
    "    songs_folder = os.path.join(base_folder, \"songs\")\n",
    "    cover_art_folder = os.path.join(base_folder, \"cover_art\")\n",
    "    os.makedirs(songs_folder, exist_ok=True)\n",
    "    os.makedirs(cover_art_folder, exist_ok=True)\n",
    "    \n",
    "    print(f\"üìÅ Output folder: {base_folder}\")\n",
    "    print(f\"üéµ Songs will be saved in: {songs_folder}\")\n",
    "    print(f\"üñºÔ∏è  Cover art will be saved in: {cover_art_folder}\")\n",
    "    \n",
    "    # === PHASE 1: CAPTURE PLAYLIST DATA ===\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"PHASE 1: Capturing Spotify Playlist Data\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Setup browser - Using the same settings as the working version\n",
    "    print(\"üîÑ Launching browser...\")\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    options.add_argument(\"--disable-web-security\")\n",
    "    options.add_argument(\"--allow-running-insecure-content\")\n",
    "    options.add_argument(\"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\")\n",
    "    \n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.requests.clear()\n",
    "    driver.get(Config.SPOTIFY_URL)\n",
    "    \n",
    "    print(f\"üåê Opened playlist: {Config.SPOTIFY_URL}\")\n",
    "    print(f\"üéØ Monitoring for PlaylistItemsPage requests to: {Config.TARGET_API_URL}\")\n",
    "    print(\"üü¢ The script will automatically scroll and capture playlist items.\")\n",
    "    \n",
    "    # Start capture and scroll threads\n",
    "    capture_thread = threading.Thread(target=capture_requests, args=(driver,))\n",
    "    capture_thread.daemon = True\n",
    "    capture_thread.start()\n",
    "    \n",
    "    if Config.AUTO_SCROLL_ENABLED:\n",
    "        scroll_thread = threading.Thread(target=auto_scroll, args=(driver,))\n",
    "        scroll_thread.daemon = True\n",
    "        scroll_thread.start()\n",
    "    \n",
    "    # Start command listener\n",
    "    command_thread = threading.Thread(target=listen_for_commands)\n",
    "    command_thread.daemon = True\n",
    "    command_thread.start()\n",
    "    \n",
    "    # Wait for capture to complete\n",
    "    while not stop_capture:\n",
    "        time.sleep(1)\n",
    "    \n",
    "    # Wait a bit for threads to finish\n",
    "    time.sleep(2)\n",
    "    driver.quit()\n",
    "    \n",
    "    if not all_playlist_items:\n",
    "        print(\"‚ùå No playlist items captured. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"‚úÖ Captured {len(all_playlist_items)} playlist items\")\n",
    "    \n",
    "    # === PHASE 2: EXTRACT ENHANCED TRACK INFORMATION ===\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"PHASE 2: Extracting Enhanced Track Information & Metadata\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    tracks = extract_enhanced_track_info(all_playlist_items, cover_art_folder)\n",
    "    \n",
    "    if not tracks:\n",
    "        print(\"‚ùå No valid tracks extracted. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    # Save enhanced track information\n",
    "    tracks_file = os.path.join(base_folder, \"enhanced_tracks_metadata.json\")\n",
    "    tracks_data = {\n",
    "        'extraction_info': {\n",
    "            'extraction_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'total_tracks': len(tracks),\n",
    "            'source_url': Config.SPOTIFY_URL,\n",
    "            'cover_art_downloaded': Config.DOWNLOAD_COVER_ART,\n",
    "            'cover_art_folder': cover_art_folder,\n",
    "            'error_handling_enabled': Config.SKIP_INVALID_TRACKS\n",
    "        },\n",
    "        'tracks': tracks\n",
    "    }\n",
    "    \n",
    "    with open(tracks_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(tracks_data, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"üìÑ Enhanced track metadata saved to: {tracks_file}\")\n",
    "    \n",
    "    # === PHASE 3: DOWNLOAD AUDIO ===\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"PHASE 3: Downloading Audio Files\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(f\"üéµ Found {len(tracks)} valid tracks to download\")\n",
    "    response = input(\"Do you want to proceed with downloading? (y/N): \").strip().lower()\n",
    "    \n",
    "    if response != 'y':\n",
    "        print(\"‚ùå Download cancelled\")\n",
    "        print(f\"üìÑ Enhanced metadata saved in: {tracks_file}\")\n",
    "        return\n",
    "    \n",
    "    # Download tracks\n",
    "    successful_downloads = 0\n",
    "    failed_downloads = 0\n",
    "    skipped_downloads = 0\n",
    "    download_log = []\n",
    "    \n",
    "    log_file = os.path.join(base_folder, \"download_log.txt\")\n",
    "    \n",
    "    for i, track in enumerate(tracks, 1):\n",
    "        try:\n",
    "            # Display track info with safe handling of empty fields\n",
    "            track_name = track.get('track_name', 'Unknown Track')\n",
    "            artists_string = track.get('artists_string', 'Unknown Artist')\n",
    "            album_name = track.get('album_name', 'Unknown Album')\n",
    "            duration_formatted = track.get('duration_formatted', '0:00')\n",
    "            added_at_formatted = track.get('added_at_formatted', '')\n",
    "            added_by_name = track.get('added_by_name', 'Unknown')\n",
    "            \n",
    "            print(f\"\\nüéµ [{i}/{len(tracks)}] {track_name} - {artists_string}\")\n",
    "            print(f\"   üìÄ Album: {album_name}\")\n",
    "            \n",
    "            if duration_formatted and duration_formatted != '0:00':\n",
    "                print(f\"   ‚è±Ô∏è  Duration: {duration_formatted}\")\n",
    "            else:\n",
    "                print(f\"   ‚è±Ô∏è  Duration: Unknown\")\n",
    "            \n",
    "            if added_at_formatted:\n",
    "                print(f\"   üìÖ Added: {added_at_formatted} by {added_by_name}\")\n",
    "            else:\n",
    "                print(f\"   üìÖ Added: Unknown date by {added_by_name}\")\n",
    "            \n",
    "            # Attempt download\n",
    "            result = search_and_download_audio(track, songs_folder)\n",
    "            download_log.append(result)\n",
    "            \n",
    "            if result['status'] == 'success':\n",
    "                successful_downloads += 1\n",
    "                print(f\"   ‚úÖ Downloaded: {result['filename']}\")\n",
    "                print(f\"   üé¨ From video: {result['video_title']}\")\n",
    "            elif result['status'] == 'skipped':\n",
    "                skipped_downloads += 1\n",
    "                print(f\"   ‚è≠Ô∏è  Skipped: {result['error']}\")\n",
    "            else:\n",
    "                failed_downloads += 1\n",
    "                print(f\"   ‚ùå Failed: {result['error']}\")\n",
    "            \n",
    "            # Log result with safe handling\n",
    "            with open(log_file, 'a', encoding='utf-8') as f:\n",
    "                f.write(f\"{i}. {track_name} - {artists_string}\\n\")\n",
    "                f.write(f\"   Album: {album_name}\\n\")\n",
    "                f.write(f\"   Duration: {duration_formatted}\\n\")\n",
    "                f.write(f\"   Added: {added_at_formatted} by {added_by_name}\\n\")\n",
    "                f.write(f\"   Status: {result['status']}\\n\")\n",
    "                f.write(f\"   Video: {result.get('video_title', 'N/A')}\\n\")\n",
    "                f.write(f\"   Error: {result.get('error', 'None')}\\n\\n\")\n",
    "            \n",
    "            time.sleep(Config.DOWNLOAD_DELAY)\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n‚èπÔ∏è  Download interrupted by user\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Unexpected error during download: {e}\")\n",
    "            failed_downloads += 1\n",
    "            \n",
    "            # Log the unexpected error\n",
    "            try:\n",
    "                with open(log_file, 'a', encoding='utf-8') as f:\n",
    "                    f.write(f\"{i}. ERROR PROCESSING TRACK\\n\")\n",
    "                    f.write(f\"   Error: Unexpected error - {str(e)}\\n\\n\")\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    # === FINAL SUMMARY ===\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"DOWNLOAD COMPLETE - ENHANCED SUMMARY WITH ERROR HANDLING\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    total_processed = successful_downloads + failed_downloads + skipped_downloads\n",
    "    \n",
    "    print(f\"üìä RESULTS:\")\n",
    "    print(f\"   Total valid tracks: {len(tracks)}\")\n",
    "    print(f\"   ‚úÖ Successful downloads: {successful_downloads}\")\n",
    "    print(f\"   ‚ùå Failed downloads: {failed_downloads}\")\n",
    "    print(f\"   ‚è≠Ô∏è  Skipped downloads: {skipped_downloads}\")\n",
    "    if len(tracks) > 0:\n",
    "        print(f\"   üìà Success rate: {(successful_downloads/len(tracks)*100):.1f}%\")\n",
    "    \n",
    "    cover_art_count = 0\n",
    "    try:\n",
    "        cover_art_count = len([f for f in os.listdir(cover_art_folder) if f.endswith('.jpg')])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    print(f\"\\nüìÅ FILES CREATED:\")\n",
    "    print(f\"   üéµ Songs folder: {songs_folder}\")\n",
    "    print(f\"   üñºÔ∏è  Cover art folder: {cover_art_folder} ({cover_art_count} images)\")\n",
    "    print(f\"   üìÑ Enhanced metadata: {tracks_file}\")\n",
    "    print(f\"   üìã Download log: {log_file}\")\n",
    "    \n",
    "    # Check for skipped tracks log\n",
    "    skipped_log_file = os.path.join(base_folder, \"skipped_tracks.log\")\n",
    "    if os.path.exists(skipped_log_file):\n",
    "        print(f\"   ‚è≠Ô∏è  Skipped tracks log: {skipped_log_file}\")\n",
    "    \n",
    "    # Save final summary\n",
    "    summary_file = os.path.join(base_folder, \"enhanced_download_summary.json\")\n",
    "    summary_data = {\n",
    "        'download_info': {\n",
    "            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'source_url': Config.SPOTIFY_URL,\n",
    "            'total_valid_tracks': len(tracks),\n",
    "            'successful_downloads': successful_downloads,\n",
    "            'failed_downloads': failed_downloads,\n",
    "            'skipped_downloads': skipped_downloads,\n",
    "            'success_rate': f\"{(successful_downloads/len(tracks)*100):.1f}%\" if tracks else \"0%\",\n",
    "            'songs_folder': songs_folder,\n",
    "            'cover_art_folder': cover_art_folder,\n",
    "            'cover_art_downloaded': cover_art_count,\n",
    "            'error_handling_enabled': Config.SKIP_INVALID_TRACKS\n",
    "        },\n",
    "        'download_results': download_log\n",
    "    }\n",
    "    \n",
    "    with open(summary_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(summary_data, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"   üìä Enhanced summary: {summary_file}\")\n",
    "    \n",
    "    if successful_downloads > 0:\n",
    "        print(f\"\\nüéâ Successfully downloaded {successful_downloads} songs with metadata!\")\n",
    "        print(f\"üéµ Your music is ready in: {songs_folder}\")\n",
    "        print(f\"üñºÔ∏è  Cover art available in: {cover_art_folder}\")\n",
    "        \n",
    "        if skipped_downloads > 0:\n",
    "            print(f\"‚è≠Ô∏è  {skipped_downloads} tracks were skipped due to invalid data\")\n",
    "            print(f\"üìã Check skipped tracks log for details: {skipped_log_file}\")\n",
    "    else:\n",
    "        print(f\"\\nüòî No songs were successfully downloaded.\")\n",
    "        print(f\"üìã Check the log files for details:\")\n",
    "        print(f\"   Download log: {log_file}\")\n",
    "        if os.path.exists(skipped_log_file):\n",
    "            print(f\"   Skipped tracks: {skipped_log_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
